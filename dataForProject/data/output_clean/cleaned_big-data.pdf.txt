logistics operations with big data analytics
ishita gupta and manjunath kamath
school of industrial engineering and management
oklahoma state stillwater ok
introduction
the concept of big data has been around for many years only in the last few years have organizations
started to understand how they can use big data to gain insightful knowledge about their business operations
which is enabling them to make better business decisions while there is no single definition big data
usually works on the principles of four vs velocity variety and veracity as the name suggests
big data is really big meaning a huge amount of data is being generated daily reaching the scale of
petabytes this data comes in all forms structured semi structured and unstructured and is pouring in
from all directions and generated by many systems and devices such as transactional systems log files
gps devices smartphones rfid readers surveillance cameras sensor networks internet of things iot
and social media finally as big data becomes an important asset for enterprises the focus is also on the
trustworthiness of data and its sources
according to gartner inc big data is high high velocity and high variety information assets that
demand cost effective innovative forms of information processing for enhanced insight and decision
making a in this article we first elaborate on the big data concept and present the storage and processing
technologies that have been developed to deal with big data we then briefly discuss the evolution of
operations finally we conclude by discussing key challenges that businesses have to face as the use of
big data analytics becomes more widespread
understanding big data
regardless of the decision to be made optimized production work schedules accurate forecasts customer
preferences data nowadays has the potential to help businesses succeed more than ever before from an
existing processes by focusing on the current business needs or create products and services as new value
propositions a challenge that organizations increasingly face is finding and working with trusted data
working with inaccurate and untrusted data can be worse than having no data at all as data requirements
and regulations become more complex organizations must be aware of where all their data is coming from
where it is getting stored and who is interacting with this data as conclusions are drawn 2
what is big data
the evolution of the world wide web has redefined the kind
of data that needs to be handled and tracked the speed at
which the information is flowing into online systems and
the number of customers a company must deal with on a
environment new definitions for big data have been
proposed with a focus on technologies that handle this data
o reilly defines big data as big data is data that exceeds
the processing capacity of conventional database systems
the data is too big moves too fast and doesn t fit the
structures of traditional database architectures to gain
value from this data organizations must choose an
alternative way to process it 3
to understand how big data is transforming businesses we
need to understand its nature as most definitions of big data
focus on the size of data in storage 4 size is important but
there are other aspects to big data namely variety
and more recently veracity 2 together they are called the 4
vs of big data velocity variety and veracity
going beyond traditional data warehouses
big data is not limited to traditional storage methods where
structured data was stored and retrieved from relational
databases data warehouses and data marts 6 here the data
is uploaded to operational data stores using extract
transform and load etl tools which extract data from
internal and external sources transform the data to fit the
operational needs and finally load the data into the data
warehouse the key point is that the data is getting cleaned
transformed and cataloged before being made available for
data mining and online analytical functions this traditional
new data sources until they are cleansed and integrated
since data is ubiquitous these days big data storage
environments need to be magnetic in nature attracting
data from all sources hence big data calls for magnetic
agile and deep mad analysis skills which differs from
tools for data analysis big data storage should allow analysts to easily process and use data rapidly
nowadays for providing high query performance and platform scalability non relational databases such as
not only sql nosql were developed for storing and managing unstructured data 7 these newer
deployment they separate data management and data storage and focus on high performance scalable data
4 vs of big data
the ability to process a large
amount of information available and
produced from transactional records to
social media from internet of things to
system logs etc
velocity the rate at which data is
getting created every second of the day
with digitization being a major
contributor
being
generated and logged than ever before 5
also the rapid adoption of social
media and the internet of things has
created a deluge of data advances in
machine learning and ai have made
previously useless data much more
useful now
variety it is the diversity of data
which organizations are witnessing
companies are used to managing and
processing a limited set of data such as
transactional
records
advances in technology have enabled
the analysis of unstructured data which
includes images voice recordings
videos and texts generated from
several platforms including social
media to deliver new insight
veracity it is not just the quality of
data but also the trustworthiness of
accuracy of data is affected by
uncertainty due to inconsistencies
incompleteness ambiguities etc
database specific languages
why big data
when organizations adopt big data as a part of their business model the first tangible question is usually
what value this big data will provide to the company 7 data must be used to make better decisions to
optimize resource consumption and improve process quality and performance it should also aim to
perform precise customer segmentation optimize customer satisfaction and increase customer loyalty
new business models should be enabled with the use of big data which complement the revenue streams
from existing products and create additional revenue from new products
the new sources of big data include industries which are taking a big step step towards digitization and as
a result data growth in the past few years has been phenomenal some of the areas where data is coming
from include social media internet browsing pattern data advertising response data financial forecasts
location information driving patterns vehicle diagnostics and traffic and weather data from sensors
monitors and forecast systems other sources of data include data from healthcare where the healthcare
industry is implementing electronic medical records and digital imaging which is used for short term public
health monitoring and long term research programs similarly low cost gene sequencing can generate
hundreds of terabytes of data that must be analyzed to look for genetic variations and potential treatment
effectiveness in life sciences 8 another area is data from video surveillance which is transitioning from
cctv to iptv cameras and recording systems that many organizations want to analyze for behavioral
patterns for security and service enhancement transportation and logistics industry has been generating
and storing enormous amount of data coming from sensors gps transceivers rfid tag readers smart
meters cell phones material handling equipment enabled with sensors etc this data can be used to
optimize operations and derive operational business intelligence to realize immediate and future business
analytics and big data analytics
data analytics is the science of analyzing raw data with the purpose of drawing conclusions about
used to extract previously unknown useful valid and hidden patterns and information from large data
sets 6 while the focus of analytics has been on inference it can also provide prescriptive insights as
explained later in this section hence analytics has a significant impact on research and technology as
businesses recognize its great potential in helping them gain competitive advantage
big data analytics is the use of advanced analytic techniques against very large and diverse data sets that
include structured semi structured and unstructured data from different sources and in different sizes from
terabytes to zettabytes b it helps in uncovering hidden patterns unknown correlations market trends
customer preferences and other useful information advanced analytics can help organizations discover
what has changed and how they should react analytics is the best way to discover new customer segments
organizations are implementing specific forms of analytics tools and techniques which include data mining
statistical analysis data visualization artificial intelligence machine learning and other data capabilities
using them now as most of these techniques adapt well to very large multi petabyte data sets
big data s worth is only realized when businesses can indulge in decision making using this data to enable
such data driven decision making organizations must use efficient processes to turn the high of
fast moving and diverse data into meaningful insights analyzing big data allows researchers and businesses
moves more efficient operations higher profits and satisfied customers and an overall competitive
advantage 6 big data analytics could be viewed as a sub process in the complete process of knowledge
extraction from big data
evolution of data analytics tools
as organization began to adopt data analytics in the late 1990s and early 2000s they faced many hurdles
data was not that easily accessible as it is now and was mostly locked down and managed by it
professionals analysts used to spend more time collecting and preparing data than analyzing it they
focused on finding more accurate and reliable solutions to business problems while keeping the solutions
simple at the same time so that business users could understand it some examples of tools used during
this time period are sas a tool for building backend data inference and modeling oracle and teradata
detailed solution suites for easy development of solutions ibm cplex a tool for solving large
optimization problems and cognos and microstrategy tools for visualization mostly in the form of
reports
in late 2000s social media giants like google and facebook and other internet based companies in general
started uncovering collecting and analyzing newer types of data which later evolved into big data in
addition to the data generated by companies in their internal operations and transactions newer data was
brought in from external sources including public data sources social media and mobile devices analysts
realized this new data was qualitatively different e g unstructured text pictures audio and video along
tools and technologies examples of which are hadoop a pioneer in distributed data storage and processing
with low cost flexibility and scalability python and r open source programming languages with vast and
ever evolving libraries for statistical data analysis tableau looker and microsoft power bi popular
descriptive predictive and prescriptive analytics
analyzing data is not limited to deriving insights from the past but it can also help businesses in predicting
future outcomes and optimizing business performance currently organizations use three types of analytics
at different stages in their decision making process descriptive predictive and prescriptive analytics as
shown in figure 1 the latter two are also referred to collectively as advanced analytics
descriptive analytics does exactly as the name suggests describe or summarize the data and convert it
into something useful it is the most basic type of analytics and almost of the organizations today use
this technique descriptive analytics is the analysis of historical data using data aggregation or data mining
and lies at the bottom of the big data analytics value chain however it is extremely valuable because it
provides insight into past behaviors which can help in understanding how several factors can influence the
organization s future
descriptive analytics is an important step to make raw data understandable to its users and it helps in
web servers using google analytics tools namely page views it can be used to determine if a strategy was
a success or not the main objective in descriptive analytics is to find the reasons behind the previous
performance patterns of the organization and to identify and address areas of weakness and strength so that
it can help the organization in strategizing
the majority of the statistics we use comes from descriptive analytics e g calculations as simple as
averages and standard deviations descriptive models use basic mathematical and statistical techniques to
derive key performance indicators that can highlight the historical trends in data stata ms excel and
spss represent the older generation of descriptive analytics tools while r and python are quickly becoming
the preferred tools in industry because of vast open source libraries and the ease of development and
deployment descriptive analytics can yield historical insights into an organization s production inventory
levels sales operations financials and customer behavior
figure 1 analytics framework by tom davenport26
of future outcomes it is one of the more sophisticated types of analytics techniques and employs statistical
techniques and machine learning it is used to detect clusters tendencies and exceptions and to predict
future trends making it a valuable tool for forecasting the foundation of predictive analytics is probability
it takes the data which the user has and tries to fill in the missing data values with best guesses it helps in
complex forecasting in marketing and sales this helps an organization to set realistic goals for business
restrain expectations and do effective planning
used tools are sas matlab r python among others the common functionality of these tools is that
they combine historical data found in pos erp crm and hr systems to identify patterns in the data and
clustering for identifying clusters finally simulation can be employed to statistically predict the outcomes
of specific decision scenarios
determine the probability of customer making timely payments other business uses include how sales
might close at the end of a year inventory level forecasts predicting what items a customer might purchase
together and other customer purchasing patterns despite all the advantages that predictive analytics brings
to the table it is important to understand that forecasting is just an estimation and its accuracy depends on
the quality and stability of data
techniques to explore a given set of options and prescribe the best possible solution for a given scenario
employing neural networks where optimization models are used to determine coefficients or weights of
neurons using training data sets once trained the neural network model can suggest the optimal course of
but also determines what the company should do it provides recommendations for the actions to be
taken to achieve optimal business performance because it has power to suggest optimal solutions
prescriptive analytics is the ultimate frontier for advanced analytics
prescriptive analytical models are complex in nature however when implemented efficiently prescriptive
analytics can have a significant impact on the decision making effectiveness of the organization technical
advancements such as cloud computing have made deployment of these complex models much easier
companies which have access to analytics experts and the powerful computing resources needed are using
experience and to make sure that the right product is being delivered at the right time airline systems use
sophisticated prescriptive models for optimal seat inventory allocation for a given price structure based on
travel factors demand levels purchasing patterns timings etc in order to maximize the revenue generated
increasing number of organizations are realizing that big data analytics gives a competitive advantage and
hence they are ensuring to choose the right kind of analytics solutions to reduce operational cost enhance
service quality and increase roi
and devices such as pos erp scm rfid gps blogs and wiki entries not to mention the unlimited
data generated from sources like cctvs digital clickstreams imagery social media posts and discussions
chain such as sensors smart devices and tags are continuously gathering real time data and providing an
this data to make insightful decisions which could help boost productivity and reduce costs
company
technique technology
system
impact
performance and ability to provide services
immersive design center
achieved product excellence reduction in time to
market through co development and co production
customers
lennox
international
integrated forecasting
system
better service level accurate prediction of customer
needs and demand automated planning and
forecasting operations
walmart
data café
inventory management with streaming analytics real
time data delivery and updates every few hours and
accurate performance analysis of each store
groupe
danone
machine learning based
planning system
improved forecasts and sales with better prediction
accuracy and greater profit margins
granarolo
machine learning
accurate forecasts reduction in delivery time by
upto and better service levels
levi strauss
iot and predictive
using intel s trusted
analytics platform
better tracking of in store items using rfid tags
updating item location and inventory helping
salesperson track misplaced item to avoid lost sales
morrisons
data intensive
forecasting method
increase in forcasting accuracy reduced inventory
stockouts and obsolescence better access to
company s logistics needs
orders packed and pushed into logistics network
before actual customer orders
flexible automation
robots bring items from storage locations to picking
and packing area
drone based delivery
goods delivered to locations less than minutes
away from an amazon warehouse
cloud based 3d
warehouse layout
planning
improve storage efficency and picking productivity
of an exiting warehouse by simulating new
configurations
camera guided agvs
and tracking
optimize picking accuracy inventory turns and
warehouse productivity in real time using inputs
from sensors such as shelf weight and weight on
forklift
quality early warning
system
reduced rework increased productivity and cost
savings higher quality standards and improved
service levels by detecting and prioritizing quality
buying analysis tool
distribution channel management better service level
and improved inventory management
accounts receivable tool optimized the resources needed for revenue
collection
merchandise
warehouse
real time monitoring and
tracking
greater visibility for customers better pallet
management optimized space utilization greater
labor productivity inventory accuracy of 9 and
improved customer satisfaction
orion
optimized delivery routes in north america
saving close to million annually reducton in
cost and emissions by selecting the right mode of
transportation
smarttruck
optimized initial route planning based on incoming
shipment information reduction in mileage and cost
and improved co2 efficiency
resilience
accuracy in risk detection prevent production
inefficiencies and revenue losses maintain service
levels and reduce emergency cost by efficiently re
routing shipments in case of unforeseen events
geovista
a tool for small and medium scale industries to
information provides realistic forecast of competitors
in a given location
address management
improves shipment delivery accuracy in areas where
quality of address information is poor real time
ddress verification to optimize route planning
logistics
raytheon
manufacturing
amazon
logivations
retail
warehouses
raytheon a major u s based defense contractor and industrial corporation made use of data analytics to
program which integrated structured and unstructured data from internal and external sources with more
ability to provide services in the face of disruptive events raytheon was able to immediately identify if a
and programs to achieve cost reductions raytheon has also developed smart factories which have the
capacity to handle big data coming from different sources like sensors instruments cad models internet
transactions simulations and digital records in the company which equips them with real time control of
various elements of the production processes for example their immersive design center idc makes
use of a 3 d immersive environment to achieve product excellence and decrease time to market through
co development and co production of products by immersive data visualization and interaction this also
the design and detect potential problems without the work and rework associated with expensive prototypes
resulting in reduced costs
lennox international a u s based cooling and heating devices manufacturing company integrated
machine learning into its forecasting system to ultimately improve customer satisfaction while coping with
their expansion throughout north america with the help of machine learning algorithms they accurately
predicted customer needs while understanding customer demand better it also helped the company to
automate its planning and forecasting operations
example a pharmaceutical company created a database of all the bids submitted for packaging this data
new packaging another example is how iot with its network of sensors embedded in millions of devices
plant engineer for replacing the faulty or near faulty part it also helps in determining when and how
critical maintenance is required by a specific machine thereby avoiding costly equipment breakdowns and
improving the overall production efficiency
daily production needs to be monitored to maintain the efficiency and output of a company big data
analytics uses the data collected from operational machines employee records and data logs of the number
of units produced to provide insights to the operations manager helping him her to make changes that are
profitable for the company manufacturers are also exploring predictive analytics to realize significant
savings in product testing and improving product quality since different products and parts require
different tests instead of performing numerous quality tests on each part data mining and pattern
recognition can be used to determine the type and number of tests truly needed for each part or product
real time data feeds to its decision makers walmart s data café based at their bentonville arkansas
headquarters takes care of most of this cloud architecture their original data infrastructure only enabled
managers to get weekly reports which prevented them from making decisions based on real time market
conditions also the reports were standardized with little room for customization data café which was
built on sap s hana in memory analytics engine enabled inventory management with streaming
analytics and provided an enterprise view of timely information flow for a large cross sectional staff
and updated every few hours furthermore the system was designed to be responsive to providing reports
and queries required by managers in the given time frame which helped them gain timely insight and make
better decisions these insights are derived from streams of internal and external data which includes
petabytes of recent transactional data and can be manipulated modeled and visualized the
importance of near real time insights is crucial since it helps managers respond to challenges in real time
as they arise for example on black friday walmart s data café provides near real time insights on the
performance of east coast stores which enables walmart to make pricing adjustments for west coast stores
before they open during a recent halloween sales analysts were able to see that two stores were not
selling a novelty cookie that was very popular in most stores using near real time data from data café it
was discovered that simple stocking oversight led to the cookies not being put on shelves in these stores
the company was able to react in real time to avoid additional lost sales data café also provides automated
alerts to managers when a metric falls below a threshold in a department this tool has reduced the problem
solving time from weeks to minutes using reliable internal and external sources of data
its customers by helping them find the product they want and avoids missing sales by locating misplaced
items using iot technology coupled with advanced analytics levi s in collaboration with intel
implemented a solution using intel s trusted analytics platform tap which helped salespersons to
items in store antenna sensors installed in the ceiling of the store to continuously track the rfid tags and
a gateway system located in the store to collect data from these sensors and send smaller data sets to a
cloud based analytical tool built on tap for detailed analysis this technology helped determine when
items are no longer in their correct place or no longer available at that time tap algorithms use data
collected overnight to determine the exact location of various groups of items and during store hours
sensors track the location of items and an algorithm determines if an item is in its assigned location if an
jeans is lying in the t shirt section or left in the fitting room the tap algorithm will generate an alert on
the salesperson to keep the item where it belongs and avoid lost sales levi s also aims to generate customer
insight using big data analytics with the data collected from sensors tracking customers in store behavior
to better understand their preferences
groupe danone a french multinational food product corporation found itself making accurate predictions
only percent of the time for responses to promotional offers which was resulting in significant losses to
the company when they implemented machine learning in their planning architecture they saw
significant improvement in both sales and forecasting similarly granarolo an italian dairy company used
machine learning to increase its forecasting accuracy by 5 percent decreased delivery times by up to
percent of the original time which resulted in better service levels morrisons one of uk s largest food
retailers was able to dramatically improve same store sales and achieve a reduction in shelf gap and
a 2 to 3 day reduction in store inventory by implementing a demand forecast and replenishment solution
from blue yonder which uses ai technology to improve demand planning and reinvigorate replenishment
based on customer behavior in every store blue yonder s data intensive forecasting methods deployed
as cloud based services is making such advanced capabilities accessible to other retailer s as well
it is now possible to re envision the planning processes by using external and internal data sources to make
real time decisions based on market trends uncertainty seasonality and other fluctuations
operations they have used various analytical tools to solve a range of problems and a few of them are
discussed here ibm s quality early warning system qews was typically deployed upstream at
chain ibm was able to reduce rework increase productivity ensure higher quality standards and improve
customer satisfaction leading to significant cost savings for a company like ibm ensuring correct
inventory levels with so many business partners was challenging they made use of ibm buying analysis
management delivery of the right product at the right time to meet customer demand while maintaining
proper inventory levels ibm also used a tool named accounts receivable which uses advanced analytics
an innovative way to use social media to monitor channels and provide valuable data on events which may
several years
help in warehouse design optimization and in improving storage efficiency and picking productivity of an
existing warehouse by simulating new configurations another example is the analysis of images and videos
captured by agvs and sensor inputs including shelf weight and weight on the forklift to monitor picking
accuracy inventory turns and warehouse productivity in real time also forklift drive picking
productivity and route optimization can be achieved by analyzing the route choices and driving behaviors
be used as a big data hub collecting real time data to identify additional sources of waste in the warehouse
operations using a hybrid of analytics and erp and wms data amazon is another warehouse automation
pioneer deploying kiva robots that bring the items racks to the picking and packing area in their
fulfillment centers with increasing pressure to reduce order to delivery times warehouses are turning to a
flexible automation strategy by using autonomous technologies such as amazon s kivac robots and
greyorange s butlerd system to increase their picking efficiency amazon has also tried to deliver goods
to people living less than minutes away from an amazon warehouse or distribution center via a drone
packed and pushed into the logistics network before the actual customer orders are placed
merchandise warehouse co mw a logistics provider of multi temperature warehouse services in the us
mid west provides services such as tempering inspection blast freezing temperature monitoring labeling
import export and packaging with such operations there is little room for error since clients food
products could get spoiled if they are not maintained at correct temperatures mw needed real time
information technology which would help them track the state of items in its warehouses at all times and
enable quality assurance with comprehensive traceability they wanted this for all operations including
inspections and holds technologies such as cctv wms electronic data interchange mobile
computers and scanners were employed to help track and analyze data to get real time information in the
warehouse and manage inventory it helped mw s customers gain visibility by having on line access to
temperatures activity reports and information about inventory levels mw s solution also includes tools
for pallet management for tracing every pallet from the time it arrives in the warehouse to until it leaves
special functionalities for cold storage such as temperature reading and recording and the ability to restrict
inventory to marked temperature zones were provided by the new system it also ensures greater labor
productivity and accuracy using workflow based warehouse management and could automate processes
designed for specific customer needs mw reaped various other benefits from this initiative like accurately
capturing billing events in real time resulting in reduced labor used for billing and paperwork the system
helped the company deal with the of catch weight where the actual weight of the product especially
meat varies when it hits the retail shelves a common problem in cold storage warehouses and food
industry increased customer satisfaction levels were also achieved since clients had real time access to
information and reports when needed the solution helped mw achieve an inventory accuracy of 9
percent from a previous 6 percent
logistics companies need to keep the goods moving at all times even in the face of disruptions such as
storms cargos getting stranded due to ship crashes and geopolitical events in order to keep the businesses
running a netherlands based logistics management company uses big data analytics on microsoft s azure
cloud to keep its customers informed about the number of goods in each container their location at a given
challenges which could delay the delivery of an order tariff calculations and fees related to the movement
conjunction with microsoft cloud technologies to combine and analyze data coming from news feeds and
identify a challenge and develop a solution to address it could be anywhere from 3 to 9 months with the
use of big data technologies this time has been brought down to a couple of weeks depending upon how
complex the problem is
manage a massive flow of freight goods and products daily while at the same time creating vast data sets
millions of shipments are tracked daily from origins to destinations generating information such as the
content weight size location and route of each individual shipment across a large number of networks
companies are exploiting and analyzing these large data sets to improve their operational efficiencies
quality logistics companies can utilize big data analytics to consolidate interpret and store the data
coming from various sources for immediate or future use based on their requirements
courier and delivery companies like ups use real time routing of deliveries using the trucks geo location
and traffic information data ups spent almost years developing its on road integrated optimization
and navigation system orion to optimize close to routes in north america in its delivery
network this system saves the company million to million annually by saving about
million miles per year which is a reduction of million gallons of fuel consumed and reducing co2
emissions by almost metric tons data mining techniques also help logistics companies deliver
services with fewer delivery attempts by using predictive analytics to predict when a customer is more
likely to be available at home costs and carbon emissions can also be reduced by selecting the right mode
of shipments and determine which ones need immediate air or truck deliveries and which still have time
and can be delivered by rail
better transportation planning can be achieved with the use of transportation management system tms
helping logistics providers make real time decisions which result in reduced costs greater reliability and
improved customer satisfaction for example data streams produced by sensors on delivery trucks beacons
which broadcast their presence to nearby devices such as computers and smartphones radar devices and
iot help a company determine the likelihood of a shipment arriving on time or getting delayed by
employing simulation models when a shipment is going to be late a carrier can make real time
and is currently employing several smart systems around their services increasing the last mile efficiencies
achieve real time optimization of delivery routes where streams of data are processed to maximize the
optimization on the last mile saving time in the delivery process when the vehicles are loaded and
unloaded manual sequencing of shipments is eliminated by the use of sensors and dynamic calculations
are used to find the optimal delivery sequence based on real time traffic conditions on the road telematic
databases are used to change the delivery route automatically dhl s smarttruck uses data mining
machine learning and other data analytics techniques to optimize the initial tour planning based on
incoming shipment on a daily basis dynamic routing system recalculates the routes depending on the
traffic situations and delivery times this also results in cost reduction and improved co2 efficiency by
reducing the miles travelled
world apart from being flexible and resilient businesses need accurate risk detection systems to keep
running smoothly big data analytics and complex event processing algorithms are used to alert businesses
when a pattern falls in the set of critical conditions such as tornadoes or floods in an area or breakdown of
fleet these alert systems send a report on the probability and impact of the risk and provide suitable
actionable insight to alleviate potential interruption with this information on hand customers can re route
designed to maintain prescribed service levels protect sales and operations and reduce emergency costs
creating a competitive advantage for the company
future economic development is often modeled on global transportation of goods and services the type of
analytics tools to extract detailed microeconomics insights from data generated by millions of daily
shipments by their distribution networks these shipment records are a valuable resource for market
intelligence research and logistics providers refine this data to substantiate existing market research
shipment records and market research outcomes the primary target group for these advanced data analytics
services are small and medium sized enterprises which lack capacity to conduct their own market research
the results from regression based analytics have high predictive value which can help these enterprises
serve a larger customer base and generate accurate forecasts based on industry geography and product
category dhl geovista is one such online geo marketing tool available for small and medium sized
dhl address management system is another useful tool making use of big data techniques to deliver
shipments more accurately customer s delivery address verification is a fundamental requirement for
any logistics provider this can be troublesome in developing countries and other remote areas where the
quality of address is usually poor due to lack of structured naming schemes for streets and buildings in an
area address management uses daily freight and parcel delivery data and matches this data with reference
data and returns the incorrect incoming data with validated data from the database in order to verify the
address in real time and optimize route planning for retailers and public sector entities
locating a new store is a strategic decision for a company and big data analytics could play an important
role here extensive data analysis is performed by the analysts in exploring customer data demographic
factors retailer network location of other competitors in the area and market potential a recent example
of this is the location for amazon s hq2 visualizing the growth of a company has become easier with the
use of data analytics since it is now possible to quickly compare the performance matrix of different sites
and identify the reasons behind such results predictive analytics comes in handy in analyzing the market
and gaining insight on questions related to global growth strategy site relocation new product introduction
price optimization is crucial for a company as having the right price for both customer and retailer keeps a
business profitable data analytics tools simplify the process of price formation which not only accounts
for the cost of production of an item but also the spending capacity of the customers and presence of
competitors in the market price flexibility buying patterns of the customers competitors prices and
seasonality are analyzed using the data coming from various sources machine learning algorithms help
identify the costs which meet the business standard by using customer segmentation to record the responses
to changes in prices furthermore using real time price optimization techniques retailers can attract new
customers and retain existing customers by adjusting the price as per market trends recommendation
engines is another great way of predicting customers behavior since they give a retailer insight into
customers reviews and opinions it also helps the retailers to increase sales and stay abreast with trends
based on machine learning algorithms recommendation engines make adjustments depending on customer
collaborative or content based data filtering is used in this process to gain useful insight which gives
leverage to retailers on customers opinions
big data challenges
companies often fail to understand what big data is its benefits and more importantly the computing and
the human infrastructure required to realize its true potential without a clear understanding of the concept
of big data adopting and implementing a project using big data tools can seriously challenge its success
we can say that handling big data is complex and companies should identify what they aim to achieve when
they de to invest in technologies using big data
the first challenge that a company is likely to face is making sense of the complex big data landscape and
reducing their dependence on legacy systems even though the industry is shifting its focus to the digital
age with adoption of iot and artificial intelligence it is still a long way before the full potential of big data
is realized industry has to develop an awareness of the various elements of the big data landscape which
include sensors to social media that collect data in memory to cloud for data storage data mining to deep
learning to convert data into useful business insights or actions any new business solution will involve a
combination of these elements and the role of people in the resulting work system is likely to change
significantly most people are resistant to change and it shows in companies when workers stick to to an
old way of thinking and doing work an example is the use of excel which to the present day remains one
of the popular tools in many companies despite having many limitations when compared to newer tools
while there is a need to educate industry to change this legacy mentality there is no need for an abrupt or
complete shift to newer tools a viable option is to slowly augment existing systems with big data analytics
tools and capabilities
with the phenomenal increase in the size of data the problem of storage space for big data has become a
real problem for many companies cloud storage is soon becoming the only viable alternative with the ever
increasing need for storage space with the maturity of the cloud computing infrastructure which includes
infrastructure for most of their computing needs but transitioning from the traditional in house computing
infrastructure to the cloud infrastructure has its own challenges according to mcafee most organizations
system before moving to the cloud for the most part cloud is cost effective compared to building and
running an it infrastructure however a company needs to carefully evaluate the cost factor based on their
academic institutions have begun to address the need for skilled professionals in the field of big data
analytics with specialized ms degrees in data science these degree programs are housed mostly in
business schools or computer science departments engineering schools to a large extent are still lagging
in providing adequate training in data science to their graduates data science professionals can manage
several new technologies such as the nosql data management framework hadoop cloud computing and
in memory analytics their skills are vital for the rapidly changing computing landscape given that
engineering schools are still looking for the right curriculum mix e g minors degree options and
certificates to train engineers in data science training employees at entry level is a challenging and
expensive proposition for companies dealing with these newer technologies when industry hires data
science professionals akin to software developers and programmers they need guidance from subject
matter experts smes to build the right tools and techniques that can help industry harness the power of
big data in the long run industry needs to quickly educate smes to understand the big data analytics
capabilities and empower them to develop big data strategies working alongside with the data science
professionals
as seen in recent times data privacy has become one of the major concerns of organizations with recent
data from multiple sources as it may compromise an individual s privacy also with an increase in the
number of connected devices within the industry data security has also become a big concern and presently
this risk is greater than ever big data analysis uses huge amounts of data for analysis and mining purposes
to reach some meaningful conclusion and security of this big data can be enhanced by using techniques
with newer secure technologies such as blockchain and data cleanroom it is possible to achieve both
partners that is completely secure from external access and where each partner can de the level of
visibility to their data blockchain a decentralized distributed database is one of the most secure options
overlooked challenge is the ethical use of data the legal infrastructure has not kept up with the rapid
development in technology which is able to collect and store vast amounts of consumer data with or without
their knowledge while it may be legal certain use of the data may be considered unethical such actions
may have a negative impact on a company as today s consumers are more educated and have experienced
negative consequences of such unethical usage
these employees need a good understanding of the business to provide solid advice resistance to
change and lack of access to data across disparate systems were the second and third biggest barriers
this results in difficulties in reconciling data from multiple sources and its subsequent analysis to gain
useful insights
the way forward
should start with a specific or narrowly defined set of objectives rather than a build it and they will come
focus the initial business case for big data analytics on customer centric objectives 7 the various
analytics whatever be the area it is desirable that the pilot project address a problem tied to a specific
business outcome the pilot project should not only help solve a business problem but also demonstrate
the effectiveness of big data analytics for the organization and its stakeholders finally for successful big
data initiatives it is essential to have strong committed sponsorship and alignment between the business
and analytics strategies 7 in the early stages of adoption the sponsor could be the cio and then shifting to
to benefit from big data analytics companies must also establish a data driven decision making culture
which calls for acting on insights from data rather than on pure managerial intuition promotion of data
sharing practices increased availability of training in data analytics and communication of the benefits of
data driven decision making are some of the strategies for promoting a data drive culture 7 while workforce
training needs to focus on improving technological and digital proficiency the future work environment
also demands training in certain soft skills the work environment is changing with the rapid introduction
of ai automation and analytics driven solutions workers need to be open to new ways of working and
have openness to agility adaptability and working in teams to cope with a constantly changing external
environment in the long run big data needs to become an integral part of the organization s operating
model there also needs to be clear ownership for big data in the organization with leadership positions
such as a chief analytics officer data science should become another established skill in the organization
acknowledgements
we would like express our gratitude to william ferrell for his constant assistance and encouragement
guidance and feedback during the formative stages of this effort we would also like to thank john
ashodian john hill ying tat leung juan ma hari padmanabhan and john paxton for carefully reading
an earlier version of this white paper and providing several constructive suggestions and feedback which
have helped us greatly improve the quality of the white paper
references
management findings from a delphi study proceedings of the 50th hawaii international conference
on system sciences
2 ibm corporation the path to data veracity ibm big data and analytics hub may
3 datastax corporation big data beyond the hype october
4 phillip russom big data analytics tdwi research
analytics aspx tc page0 m dxc technology company five industries where big data is making a difference november
five_industries_where_big_data_is_making_a_difference 4aa5 6292enw pdf
6 nada elgendy and ahmed elragal big data analytics a literature review paper in perner p
computer science vol springer cham
3 8_16
communications of the association for information systems article
8 richard l villars carl w olofson and matthew eastwood big data what it is and why you
should care international data corporation
between and insights to industries computers and industrial engineering
landscape part 1 february
lorenzo romano big data analytics a key ingredient for agility in manufacturing may
joe mckendrick walmart s gigantic private cloud for real time inventory control january
real time data
rt insights team levi s real time tracking of jeans rfid in retail april
jda store replenishment at morrisons
morrisons case study
logivation
rt insights team using mobile device for a real time warehouse
industry
third party logistics study
leadership 2017stateoflogisticsreport_new ashx
ups orion backgrounder
s id data driven logistics the growing use of predictive analytics july
data driven logistics the growing use of predictive analytics
martin jeske moritz grüner and frank weiß big data in logistics a dhl perspective on how
to move beyond the hype december
mckinsey company big data analytics and the future of marketing and sales march
20insights ebook 20big 20data 20analytics 20and 20the 20future 20of 20marketing 20sal
es big data ebook ashx
gurobi optimization the power of analytics accessed september 8
transmetrics big data and big roadblocks how the logistics industry can overcome its big
data challenges march
challenges
andrew mcafee what every ceo needs to know about the cloud harvard business review
bharat bhargava rohit ranchal and lotfi ben othmane secure information sharing in digital
david meer a call to action on big data forbes october