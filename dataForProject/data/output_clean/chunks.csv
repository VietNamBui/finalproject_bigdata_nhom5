chunk_id,source,text,token_count
2_iis_2015_81-90.pdf_0,2_iis_2015_81-90.pdf,"today big data draws a lot of attention in the it world the rapid rise of the internet and the digital economy has
fuelled an exponential growth in demand for data storage and analytics and it department are facing tremendous
collecting and storing more data than ever before is because their business depends on it the type of information
being created is no more traditional database driven data referred to as structured data rather it is data that
include documents images audio video and social media contents known as unstructured data or big data big
take proactive actions and give way to better strategic decision making further this paper analyzes the adoption
usage and impact of to the business value of an enterprise to improve its competitive advantage
using a set of data algorithms for large data sets such as hadoop and mapreduce
big data analytics hadoop mapreduce
introduction
traditional database big data consists of different types of key technologies like hadoop hdfs nosql
mapreduce mongodb cassandra pig hive and hbase that work together to achieve the end goal like
extracting value from data that would be previously considered dead according to a recent market report published
by transparency market research the total value of big data was estimated at 6 3 billion as of but by
it s expected to reach the staggering level of 3 billion that s almost a percent increase forrester
research estimates that organizations effectively utilize less than 5 percent of their available data this is because
the rest is simply too expensive to deal with big data is derived from multiple sources it involves not just
traditional relational data but all paradigms of unstructured data sources that are growing at a significant rate for
instance machine derived data multiplies quickly and contains rich diverse content that needs to be discovered
another example human derived data from social media is more textual but the valuable insights are often
overloaded with many possible meanings
reflect the challenges of data that are too vast too unstructured and too fast moving to be
managed by traditional methods from businesses and research institutions to governments organizations now
routinely generate data of unprecedented scope and complexity gleaning meaningful information and competitive
advantages from massive amounts of data has become increasingly important to organizations globally trying to
efficiently extract the meaningful insights from such data sources quickly and easily is challenging thus analytics
has become inextricably vital to realize the full value of big data to improve their business performance and
increase their market share the tools available to handle the velocity and variety of big data have
improved greatly in recent years in general these technologies are not prohibitively expensive and much of the
software is open source hadoop the most commonly used framework combines commodity hardware with open
source software it takes incoming streams of data and distributes them onto cheap disks it also provides tools for
analyzing the data however these technologies do require a skill set that is new to most it departments which will
need to work hard to integrate all the relevant internal and external sources of data although attention to technology
isn t sufficient it is always a necessary component of a big data strategy this paper discusses some of the most
commonly used big data technologies mostly open source that work together as a system for
leveraging large quantities of unstructured data to make more informed decisions
review of literature
capture storage and analysis data sources extend beyond the traditional corporate database to include emails
mobile device outputs and sensor generated data where data is no longer restricted to structured database records
but rather unstructured data having no standard formatting since big data and analytics is a relatively new
and evolving phrase there is no uniform definition various stakeholders have provided diverse and sometimes
contradictory definitions one of the first widely quoted definitions of big data resulted from the gartner report of
gartner proposed that big data is defined by three v s velocity and variety gartner expanded its
definition in to include veracity representing requirements about trust and uncertainty pertaining to data and
the outcome of data analysis in a report idc defined the 4th v as value highlighting that big data
information from call logs mobile banking transactions online user generated content such as blog posts and
tweets online searches and images which can be transformed into valuable business information using
computational techniques to unveil trends and patterns between datasets
another dimension of the big data definition involves technology big data is not only large and complex but it
requires innovative technology to analyze and process in the national institute of standard and technology
technology big data exceed the capacity or capability of current or conventional methods and systems and enable
practitioners have difficulties to incorporate it into their complex decision making that adds business value in
mckinsey company conducted a survey of 1 executives across various regions industries and company
sizes in which percent of respondents said that their companies are focusing big data efforts on cuser
insights segmentation and targeting to improve overall performance an even higher number of respondents
percent said their companies should focus efforts on using data and analytics to generate these insights yet just
one fifth said that their organizations have fully deployed data and analytics to generate insights in one business unit
or function and only percent use data to generate insights across the company as these survey results show the
question is no longer whether big data can help business but how can business derive maximum results from big
predictive analytics
predictive analytics is the use of historical data to forecast on consumer behavior and trends it is the use of
past historical data to predict future trends this analysis makes use of the statistical models and machine learning
algorithms to identify patterns and learn from historical data predictive analysis can also be defined as a
process that uses machine learning to analyze data and make predictions
sixty seven percent of businesses aim at using predictive analytics to create more strategic marketing campaign in
future and sight competitive advantage as the prime benefit of predictive analysis broadly speaking
search typically a large e commerce site offers thousands of product and services for sale navigating and
searching for a product out of thousands on a website could be a major setback to consumers however with the
closely suit the consumer s taste
using a technology called collaborative filtering a database of historical user preferences is created when a new
cuser access the ecommerce site the cuser is matched with the database of preferences in order to discover a
preference class that closely matches the cuser taste these products are then recommended to the cuser
another technology that is used in ecommerce is the clustering algorithm clustering algorithm works by identifying
groups of users that have similar preferences these users are then clustered into a single group and are given a
unique identifier
new cusers cluster are predicted by calculating the average similarities of the individual members in that cluster
hence a user could be a partial member of more than one cluster depending of the weight of the user s average
opinion advanced analytics is defined as the scientific process of transforming data into insight for making
better decisions as a formal discipline advanced analytics have grown under the operational research domain
there are some fields that have considerable overlap with analytics and also different accepted classifications for
the types of analytics 2
big data technologies
apache flume
apache flume is a distributed reliable and available system for efficiently collecting aggregating and moving large
amounts of log data from many different sources to a centralized data store flume deploys as one or more agents
each contained within its own instance of the java virtual machine jvm agents consist of three pluggable
components sources sinks and channels flume agents ingest incoming streaming data from one or more sources
data ingested by a flume agent is passed to a sink which is most commonly a distributed file system like hadoop
multiple flume agents can be connected together for more complex workflows by configuring the source of one
agent to be the sink of another flume sources listen and consume events events can range from newline terminated
strings in stdout to http posts and rpc calls it all depends on what sources the agent is configured to use
flume agents may have more than one source but at the minimum they require one sources require a name and a
type the type then dictates additional configuration parameters
channels are the mechanism by which flume agents transfer events from their sources to their sinks events written
to the channel by a source are not removed from the channel until a sink removes that event in a transaction this
allows flume sinks to retry writes in the event of a failure in the external repository such as hdfs or an outgoing
network connection for example if the network between a flume agent and a hadoop cluster goes down the
channel will keep all events queued until the sink can correctly write to the cluster and close its transactions with the
channel sink is an interface implementation that can remove events from a channel and transmit them to the next
agent in the flow or to the event s final destination and also sinks can remove events from the channel in
transactions and write them to output transactions close when the event is successfully written ensuring that all
events are committed to their final destination
apache sqoop
apache sqoop is a cli tool designed to transfer data between hadoop and relational databases sqoop can import
data from an rdbms such as mysql or oracle database into hdfs and then export the data back after data has
been transformed using mapreduce sqoop also has the ability to import data into hbase and hive sqoop connects
to an rdbms through its jdbc connector and relies on the rdbms to describe the database schema for data to be
imported both import and export utilize mapreduce which provides parallel operation as well as fault tolerance
during import sqoop the table row by row into hdfs because import is performed in parallel the output in
hdfs is multiple files
apache pig
apache s pig is a major project which is lying on top of hadoop and provides higher level language to use
hadoop s mapreduce library pig provides the scripting language to describe operations like the reading filtering
and transforming joining and writing data which are exactly the same operations that mapreduce was originally
designed for instead of expressing these operations in thousands of lines of java code which uses mapreduce
directly apache pig lets the users express them in a language that is not unlike a bash or perl script
pig was initially developed at yahoo research around but moved into the apache software foundation in
unlike sql pig does not require that the data must have a schema so it is well suited to process the
complete like sql which means it is at least as powerful as a relational algebra turing completeness requires
conditional constructs an infinite memory model and looping constructs
apache hive
hive is a technology developed by facebook that turns hadoop into a data warehouse complete with a dialect of
sql for querying being a sql dialect hiveql is a declarative language in piglatin you specify the data flow
but in hive we describe the result we want and hive figures out how to build a data flow to achieve that result
unlike pig in hive a schema is required but you are not limited to only one schema like piglatin and sql
hiveql itself is a relationally complete language but it is not a turing complete language
apache zookeeper
apache zoo keeper is an effort to develop and maintain an open source server which enables highly reliable
distributed coordination it provides a distributed configuration service a synchronization service and a naming
configuration information zookeeper is especially fast with workloads where to the data are more common
than writes the ideal write ratio is about 1 zookeeper is replicated over a set of hosts called an ensemble
and the servers are aware of each other and there is no single point of failure
figure 1 intel manager for hadoop 3
mongodb
mongodb is an open source document oriented nosql database that has lately attained some space in the data
industry it is considered as one of the most popular nosql databases competing today and favors master slave
replication the role of master is to perform and writes whereas the slave confines to copy the data received
from master to perform the operation and backup the data the slaves do not participate in write operations
but may select an alternate master in case of the current master failure mongodb uses binary format of json like
documents underneath and believes in dynamic schemas unlike the traditional relational databases the query
system of mongodb can return particular fields and query set compass search by fields range queries regular
expression search etc and may include the user defined complex javascript functions as hinted already
mongodb practice flexible schema and the document structure in a grouping called collection may vary and
common fields of various documents in a collection can have disparate types of the data
develop the cusized systems that use mongodb as their backend player there is an increasingly demand of
in order to efficiently address the challenges of big data the leading vendor developed the oracle nosql database
it was built by oracle berkeley db team and the berkeley db java edition is the building block of oracle nosql
berkeley db is a robust and scalable key value store and used as the underlying storage for several popular data
model such as amazon dynamo geniedb memcachedb and voldemort
there are several other database systems that discern the strength of berkeley db and have attained greater
scalability throughput and reliability with little tuning efforts it is an efficient and a resilient transaction model that
oracle database and hadoop it offers scalable throughput with bounded latency the model very well
accommodates the horizontal scaling with dynamic annexation of new capacity citing high availability the design
of high availability rapid failover in the event of a node failure etc are achieved by replicating the storage nodes
apache cassandra
apache cassandra is the yet another open source nosql database solution that has gained industrial reputation
which is able to handle big data requirements it is a highly scalable and high performance distributed database
businesses it has a built for scale architecture that can handle petabytes of information and thousands of concurrent
users operations per second as easily as it can manage much smaller amount of data and user traffic it has a peer to
peer design that offers no single point of failure for any database process or function in addition to the location
independence capabilities that equate to a true network independent method of storing and accessing data data can
data is represented in cassandra via column families that are dynamic in nature and accommodate all modifications
online
apache hadoop
the apache hadoop software library is a framework that enables the distributed processing of large data sets across
clusters of computers it is designed to scale up from single servers to thousands of machines with each offering
local computation and storage the basic notion is to allow a single query to find and collect results from all the
technological challenges in software systems research today is to provide mechanisms for storage manipulation and
information retrieval on large amount of data web services and social media produce together an impressive
amount of data reaching the scale of petabytes daily facebook these data may contain valuable
information which sometimes is not properly explored by existing systems most of this data is stored in a non
structured manner using different languages and format which in many cases are in compatible
parallel and distributed computing currently has a fundamental role in data processing and information extraction of
large datasets over the last years commodity hardware became part of clusters since the x86 platform cope with
the need of having an overall better cost performance ratio while decreasing maintenance cost apache hadoop is a
manipulation of large amount of data the framework was designed over the mapreduce paradigm and uses the
hdfs as a storage file system hadoop presents key characteristics when performing parallel and distributed
computing such as data integrity availability scalability exception handling and failure recovery
hadoop is a popular choice when you need to filter sort or pre process large amounts of new data in place and
distill it to generate denser data that theoretically contains more information pre processing involves filtering new
data sources to make them suitable for additional analysis in a data warehouse hadoop is a top level open source
distributions packaging the basic software stack with other hadoop software projects such as apache hive apache
pig and apache sqoop these distributions must integrate with data warehouses databases and other data
management products so data can move among hadoop clusters and other environments to expand the data pool to
process or query
figure 2 data architecture with hadoop integrated with existing data system
mapreduce is the original massively scalable parallel processing framework commonly used with hadoop and
other components such as the hadoop distributed file system hdfs and yarn yarn can be described as a
large scale distributed operating system for big data implementations as hadoop has matured the batch oriented
streaming processing and advanced implementations such as the aforementioned machine learning
mapreduce
mapreduce is the model of distributed data processing introduced by google in the fundamental concept of
mapreduce is to divide problems into two parts a map function that processes source data into sufficient statistics
and a reduce function that merges all sufficient statistics into a final answer by definition any number of
concurrent map functions can be run at the same time without intercommunication once all the data has had the
batch processing and high speed data retrieval common in web search scenarios mapreduce provides the fastest
most cost effective and most scalable mechanism for returning results today most of the leading technologies for
managing big data are developed on mapreduce with mapreduce there are few scalability limitations but
leveraging it directly does require writing and maintaining a lot of code
apache splunk
splunk is a general purpose search analysis and reporting engine for time series text data typically machine data
compliance it operations management and providing analytics for the business the splunk engine is optimized for
quickly indexing and persisting unstructured data loaded into the system specifically splunk uses a minimal
schema for persisted data events consist only of the raw event text implied timestamp source typically the
filename for file based inputs source type an indication of the general type of data and host where the data
originated
once data enters the splunk system it quickly proceeds through processing is persisted in its raw form and is
indexed by the above fields along with all the in the raw event text indexing is an essential element of the
canonical super grep use case for splunk but it also makes most retrieval tasks faster any more sophisticated
processing on these raw events is deferred until search time this serves four important goals indexing speed is
increased as minimal processing is performed bringing new data into the system is a relatively low effort exercise as
no schema planning is needed the original data is persisted for easy inspection and the system is resilient to change
as data parsing problems do not require reloading or re indexing the data
big data framework
apache spark
apache spark an open source big data processing framework built around speed ease of use and sophisticated
analytics it was originally developed in in uc berkeley s amp lab and open sourced in as an apache
project hadoop as a big data processing technology has been around for ten years and has proven to be the solution
of choice for processing large data sets mapreduce is a great solution for one pass computations but not very
efficient for use cases that require multi pass computations and algorithms each step in the data processing
workflow has one map phase and one reduce phase and you ll need to convert any use case into mapreduce pattern
to leverage this solution spark takes mapreduce to the next level with less expensive shuffles in the data
processing with capabilities like in memory data storage and near real time processing the performance can be
several times faster than other big data technologies
workflows it provides a higher level api to improve developer productivity and a consistent architect model for big
data solutions spark holds intermediate results in memory rather than writing them to disk which is very useful
especially when you need to work on the same dataset multiple times it s designed to be an execution engine that
works both in memory and on disk spark operators perform external operations when data does not fit in memory
spark can be used for processing datasets that larger than the aggregate memory in a cluster spark will attempt to
store as much as data in memory and then will spill to disk it can store part of a data set in memory and the
remaining data on the disk you have to look at your data and use cases to assess the memory requirements with
this in memory data storage spark comes with a great performance advantage
programming languages like scala java python clojure and r other than spark core api there are additional
libraries that are part of the spark ecosystem and provide additional capabilities in spark
streaming is one among the spark library that can be used for processing the real time streaming data this is based
on micro based on micro batch style of computing and processing spark sql provides the capabilities to expose the
spark datasets over jdbc api and allow running the sql like queries on spark data using traditional bi and
visualization tools mllib graphx are some other libraries from spark
competitive advantages
thomas h davenport was perhaps the first to observe in his harvard business review article published in january
competing on analytics how companies who orientated themselves around fact based management
reality is that it takes continuous improvement to become an analytics driven organization in a presentation given at
the strata new york conference in september mckinsey company showed the eye opening year
category growth rate differences see figure 7 below between businesses that smartly use their big data and those
that do not
amazon uses big data to monitor track and secure 1 5 billion items in its inventory that are laying around
when a cuser will purchase a product and pre ship it to a depot close to the final destination wal mart handles
more than a million cuser transactions each hour imports information into databases to contain more than
can generate to times the data of conventional bar code systems ups deployment of telematics in their
freight segment helped in their global redesign of logistical networks 6 amazon is a big data giant and the largest
online retail store the company pioneered e commerce in many different ways but one of its biggest successes was
the personalized recommendation system which was built from the big data it gathers from its millions of
cusers transactions
the u s federal government collects more than raw and geospatial datasets from agencies and sub
access to information not deemed private or classified professional social network linkedin uses data from its more
than million users to build new social products based on users own definitions of their skill sets silver spring
networks deploys smart two way power grids for its utility cusers that utilize digital technology to deliver more
reliable energy to consumers from multiple sources and allow homeowners to send information back to utilities to
trends to identify problems with its healthcare system revealing services that were both medically ineffective and
expensive
conclusion
today s technology landscape is changing fast organizations of all shapes and sizes are being pressured to be data
driven and to do more with less even though big data technologies are still in a nascent stage relatively speaking
the impact of the 3v s of big data which now is 5v s cannot be ignored the time is now for organizations to begin
planning for and building out their hadoop based data lake organizations with the right infrastructures talent and
they can use big data to unveil new patterns and trends gain additional insights and begin to find answers to
what s learned the more likely they are to reveal answers that can add value to the top line of the business this is
where the returns on big data investments multiply and the transformation begins harnessing big data insight
data driven decisions always tend to be better decisions
references
1 apache software foundation apache zookeeper retrieved april 5 from
2 chae b sheu c yang c and olson d the impact of advanced analytics and data accuracy on
3 chambers c raniwala a adams s henry r bradshaw r and weizenbaum n flume java
easy efficient data parallel pipelines google inc retrieved april 1 from
4 cisco systems cisco ucs common platform architecture version 2 cpa v2 for big data with
comprehensive data protection using intel distribution for apache hadoop retrieved march from
th_intel html
5 datastax corporation october big data beyond the hype why big data matters to you white
paper retrieved march from
bigdata pdf
6 davenport t patil d data scientist the sexiest job of the 21st century harvard business review
7 dhawan s rathee s using hadoop components like pig and hive american
international journal of research in science technology engineering mathematics retrieved
service white paper retrieved from
journey big data ba wp pdf
emc corporation big data big transformations white paper retrieved from
emc solutions group july big data as a service white paper retrieved from
enterprise hadoop the ecosystem of projects retrieved from
george l september getting started with big data architecture retrieved april 5 from
ibm corporation ibm big data platform retrieved from
software in data bigdata enterprise html
intel corporation extract transform and load big data with apache hadoop white
paper retrieved april 3 from
with hadoop pdf
mcclary d june acquiring big data using apache flume retrieved march 3 from
millard s big data brewing value in human capital management ventana research retrieved
april 2 from
capital management
mosavi a and vaezipour a developing effective tools for predictive analytics and informed
decisions technical report of tallinn
oracle corporation march advanced analytics in oracle database white
paper retrieved march 5 from
analytics advanced analytics wp 12c pdf sssourcesiteid ocomen
oracle enterprise architecture april an enterprise architect s guide to big data reference
architecture overview white paper retrieved from
penchikala s january big data processing with apache spark part 1 introduction retrieved from
retrieved april5 from
and tuning information into intelligence 1st edition pearson nj
sarwar b karypis g konstan j and riedl j recommendation systems for large e commerce
scalable neighborhood formation using clustering in proceedings of the fifth international conference on
computer and information technology 1
sorkin s splunk technical paper large scale unstructured data retrieval and analysis using
splunk retrieved april from
briefs splunk and mapreduce pdf
the bloor group ibm and the big data information architecture retrieved april 3 from
tiwari s using oracle berkeley db as a nosql data store retrieved april from
us 3 bn by retrieved june from
villars r l olofson c w eastwood m june big data what it is and why you should care idc
white paper framingham ma idc
wolpe t march how facebook is speeding up the pesto sql query engine retrieved april 3
zahari et al spark cluster computing with working sets retrieved april 7 from",4696
48077-157-151840-1-10-20200520.pdf_0,48077-157-151840-1-10-20200520.pdf,"thông tin và tư liệu 2
big data và xu hướng ứng dụng trong hoạt động thông tin thư viện
tóm tắt big data là một thuật ngữ được sử dụng để chỉ những bộ dữ liệu khổng lồ chủ yếu không
có cấu trúc được thu thập từ nhiều nguồn khác nhau big data có nhiều tác động ứng dụng và được
xem như một yếu tố quyết định đến việc phát triển mang lại lợi thế cạnh tranh cho tổ chức bài viết
tổng quan lược sử các quan điểm về big data đồng thời nhấn mạnh vào các xu hướng ứng dụng
trong hoạt động thông tin thư viện
từ khóa big data dữ liệu lớn hoạt động thư viện
big data is a term used to refer to huge mostly unstructured datasets collected from
factor in the development bringing competitive advantages to the organization the overview paper
activities
big data library activities
1 lược sử các quan điểm về big data
hiện nay chưa có một định nghĩa chính
xác cho thuật ngữ big data big được ghi
controlled demand paging for out of core
visualization của michael cox và david
ellsworth được trình bày tại hội nghị ieee lần
thứ 8 vào tháng năm ý tưởng đưa
ra ban đầu là dung lượng thông tin đã tăng
quá lớn tới mức các bộ nhớ máy tính dùng để
xử lý không còn đủ số lượng cần khảo sát do
vậy các kỹ sư cần cải tạo các công cụ để có
thể phân tích được tất cả các thông tin
tháng 8 năm steve bryson david
kenwright michael cox david ellsworth và
robert haimes đăng bài visually exploring
gigabyte data sets in real time trên tạp chí
communications of the acm đây là bài viết
đầu tiên sử dụng thuật ngữ big data các
tác giả nhận định những chiếc máy tính
mạnh là lợi thế cho việc khảo sát nhiều lĩnh
vực cũng có thể là bất lợi tính toán nhanh
chóng tạo ra một lượng lớn dữ liệu nếu trước
kia bộ dữ liệu megabyte đã từng được coi
là lớn thì bây giờ chúng ta có thể tìm thấy
những bộ dữ liệu của cá nhân vào khoảng
tháng năm francis x diebold
trình bày tại đại hội thế giới lần thứ viii của
hiệp hội kinh tế lượng bài viết big data
dynamic factor models for macroeconomic
measurement and forecasting trong bài
viết này tác giả khẳng định gần đây nhiều
học xã hội vốn đang buộc phải đương đầu với
khó khăn đã thu được lợi từ hiện tượng big
data và đã gặt hái được nhiều thành công big
data chỉ sự bùng nổ về số lượng và đôi khi
chất lượng khả năng liên kết cũng như độ
sẵn sàng của dữ liệu chủ yếu là kết quả của
những tiến bộ gần đây và chưa từng có trong
việc ghi lại dữ liệu và công nghệ lưu trữ 4
tháng 2 năm doug laney nhà
phân tích của tập đoàn meta công bố nghiên
cứu 3d data managment controlling data
velocity and variety laney cho
rằng những thách thức và cơ hội nằm trong
việc tăng trưởng dữ liệu có thể được mô tả
bằng mô hình 3vs tăng về số lượng lưu trữ
tăng về tốc độ xử lý velocity và
tăng về chủng loại variety 3 một thập kỷ
sau mô hình 3vs đã trở thành thuật ngữ
được chấp nhận rộng rãi trong việc xác định
dữ liệu lớn ba chiều nhiều công ty và tổ chức
nghiên cứu trao đổi
thông tin và tư liệu 2 thông tin và tư liệu 1
trong lĩnh vực công nghệ thông tin tiếp tục sử
dụng mô hình 3vs này để định nghĩa big
tháng năm randal e bryant
randy h katz và edward d lazowska
công bố bài viết big data computing
creating revolutionary breakthroughs in
commerce science and society trong đó
miêu tả cũng như công cụ tìm kiếm đã làm
thay đổi cách chúng ta tiếp cận thông tin các
hình thức khác của sử dụng big data có thể
sẽ làm thay đổi cách hoạt động của các công
viên y tế quốc phòng và tình báo sử dụng
big data có lẽ là đổi mới lớn nhất trong công
nghệ máy tính suốt một thập kỷ qua chúng
tôi chỉ mới bắt đầu nhìn thấy tiềm năng của
nó trong việc thu thập sắp xếp và xử lý dữ
liệu của tất cả các tầng lớp xã hội một khoản
đầu tư dù khiêm tốn của chính phủ liên bang
sẽ thúc đẩy phát triển và mở rộng nó
tháng 2 năm kenneth cukier đăng
trên tờ the economist newspaper bài viết
data data everywhere cukier viết thế
giới chứa một số lượng thông tin số lớn đến
mức không tưởng và càng ngày càng được
nhân rộng với tốc độ nhanh hơn bao giờ hết
hiệu quả đã được thể hiện ở khắp mọi nơi từ
tính đã đặt ra một thuật ngữ mới cho hiện
tượng này big data 8
tháng 5 năm danah boyd và kate
crawford đưa ra luận điểm của họ trong
bài critical question for big data trên tờ
information communications and society
các tác giả định nghĩa big data như là một
hiện tượng văn hóa công nghệ và học thuật
dựa trên sự tương tác của 1 công nghệ tối
đa hóa sức mạnh tính toán và độ chính xác
thuật toán để thu thập phân tích liên kết và
so sánh các tập dữ liệu lớn 2 phân tích tạo
ra trên dữ liệu lớn để xác định mô hình cho
tuyên bố kinh tế xã hội kỹ thuật và pháp lý 3
thần thoại niềm tin phổ biến rằng dữ liệu lớn
cung cấp một hình thức cao hơn của trí thông
minh và kiến thức có thể tạo ra những hiểu
biết mà trước đây không thể với hào quang
của sự thật khách quan chính xác 2
sau đó gartner công ty nghiên cứu và
tư vấn công nghệ thông tin bổ sung thêm
rằng big data ngoài 3 tính chất số lượng
tốc độ xử lý và chủng loại thì còn phải cần
đến các dạng xử lý mới để đưa ra quyết định
khám phá sâu vào sự vật sự việc và tối ưu
hóa các quy trình làm việc 5 cùng quan
điểm đó tan jee toon cho rằng big data
là khối lượng dữ liệu rất lớn được tạo ra từ
mọi thứ xung quanh chúng ta từ các thiết bị
kỹ thuật số như di động video hình ảnh tin
nhắn tới các thiết bị cảm biến các máy móc
được kết nối tới các trang web và mạng xã
hội big data có đặc điểm là được sinh ra với
khối lượng tốc độ velocity độ đa
dạng variety và tính xác thực veracity rất
năm gartner đưa ra khái niệm
mới về big data bằng mô hình 5vs gồm
khối lượng velocity tốc độ
variety tính đa dạng veracity tính xác
thực và value giá trị trong đó là
khối lượng big data được tạo ra mỗi ngày
công nghệ big data có thể lưu trữ và sử
dụng những tập dữ liệu trong các hệ thống
phân tán nơi mà dữ liệu chỉ được lưu trữ một
phần tại các điểm khác nhau và được tập hợp
bởi phần mềm velocity là tốc độ dữ liệu mới
được tạo ra và tốc độ dữ liệu chuyển động
công nghệ big data có thể phân tích dữ liệu
ngay khi chúng được tạo ra mà không cần lưu
giữ chúng trong các cơ sở dữ liệu variety là
các kiểu khác nhau của dữ liệu công nghệ
big data cho phép lưu trữ các loại dữ liệu
có cấu trúc truyền thống được lưu trữ trong
các bảng hoặc các cơ sở dữ liệu quan hệ và
phi cấu trúc bao gồm các thông điệp trao
đổi của mạng xã hội các hình ảnh dữ liệu
cảm biến video tiếng nói veracity là tính
hỗn độn hoặc tính tin cậy của dữ liệu công
nghệ big data và phân tích dữ liệu cho phép
kiểm soát những loại dữ liệu này value là giá
trị của dữ liệu việc tiếp cận big data sẽ chỉ
có ý nghĩa khi chúng ta chuyển được dữ liệu
thành những thứ có giá trị đây là khái niệm
đầy đủ về 5 tính chất của big data 5
nghiên cứu trao đổi
thông tin và tư liệu 2
thông tin và tư liệu 1
2 xu hướng ứng dụng big data trong hoạt
động thông tin thư viện
ngày nay một lượng lớn dữ liệu số có thể
được tạo ra bởi những hệ thống liên kết với
các mạng xã hội theo howe d chỉ
lượng dữ liệu đang tăng lên với tốc độ tăng
trưởng theo cấp số nhân 7 số lượng dữ
liệu ngày càng tăng là xu thế phát triển trong
nhiều lĩnh vực khác nhau và dữ liệu lớn big
data được sử dụng rộng rãi trong các lĩnh
vực tổ chức với nhiều mục đích khác nhau
các công ty sử dụng big data để tìm hiểu
hành vi tiêu dùng của khách hàng để đề xuất
mua sắm cá nhân hóa cho từng đối tượng dựa
trên thông tin thu thập được ebay facebook
dụng big data để tìm ra những khám phá
gene của con người việc sử dụng big data
trong hoạt động thông tin thư viện đã bắt
đầu được quan tâm nghiên cứu campbell
d grant cowan scott r phân tích
nghịch lý về quyền riêng tư khi xem xét lại giá
trị cốt lõi của thư viện trong thời đại big data
và dữ liệu liên kết 1 kim young seok
phân tích big data trong các hoạt động và
dịch vụ thư viện công cộng bằng phương pháp
khuôn mặt chernoff 9 gerrard d mooney
j và thompson d xem xét kiến trúc
của các hệ thống bảo quản kỹ thuật số hỗ trợ
phân tích dữ liệu các bộ tài nguyên được bảo
tồn ở quy mô lớn và phân tích dự báo việc sử
dụng big data của các nhà nghiên cứu trong
thời gian tới 6 waqar ahmed và kanwal
ameen tổng quan các khái niệm về
big data và đo lường xu hướng liên quan của
big data trong lĩnh vực quản lý thông tin và
thư viện ye chunlei nghiên cứu
về công nghệ chính của dịch vụ big data
trong thư viện đại học zhan ming widén
gunilla nghiên cứu vai trò của thư
viện công cộng trong thời đại big data
li shuqing jiao fusen zhang yong xu xia
nghiên cứu các vấn đề và thay đổi của
thư viện số trong thời đại big data từ góc độ
dịch vụ người dùng tin các nghiên cứu
bằng những cách tiếp cận khác nhau đã đề
cập đến nhiều vấn đề của hoạt động thư viện
trong thời đại big data bàn về xu hướng ứng
dụng của big data trong hoạt động thư viện
tuy chưa có một nghiên cứu đầy đủ và trực
tiếp nào nhưng có thể tổng hợp thành các xu
hướng chính như sau
một là tổ chức lưu trữ bảo quản dữ liệu
marydee ojala nhận định các thư viện
đã phải đối mặt với big data từ trước khi thuật
ngữ này xuất hiện và trở nên thông dụng như
ngày nay bộ sưu tập các tài nguyên số được
bảo tồn đang trở thành nguồn big data trong
các thư viện khối lượng và tính đa dạng dữ
liệu đang tăng lên nhanh chóng đòi hỏi các
thư viện phải có phương pháp tổ chức lưu trữ
bảo quản dữ liệu hợp lý nguồn dữ liệu
thư viện bao gồm nguồn dữ liệu mô tả tài liệu
thư viện nguồn tài nguyên số hóa tài liệu thư
viện nguồn tài liệu số thư viện bổ sung qua
việc mua hay sử dụng chung nguồn dữ liệu
khảo sát thư viện dữ liệu định tính dữ liệu
tương tác xã hội trước đây các thư viện
đều lưu trữ dữ liệu ngoại tuyến trên các cuộn
băng đặt trong các cơ sở lưu trữ trước tác
động của công nghệ thông tin và cuộc cách
mạng công nghiệp lần thứ tư các thư viện
đã xem xét lại cách thức lưu trữ truyền thống
và triển khai một giải pháp lưu trữ tiết kiệm
chi phí hiệu quả dữ liệu được lưu trữ theo
hai cách cả trên các thiết bị ngoại tuyến thẻ
nhớ sd ổ cứng ngoài ổ đĩa flash và lưu trữ
trực tuyến trên đám mây với phương thức
kết hợp sử dụng băng từ để bảo quản lưu trữ
sử dụng ổ đĩa cho các thông tin thường xuyên
được yêu cầu và sử dụng lưu trữ đám mây
cho các big data các thư viện hướng đến
việc xác định khả năng truy cập tài nguyên
thư viện bao gồm cả tài nguyên vật chất và
dữ liệu xác định nhu cầu của người dùng
tin và lập kế hoạch vòng đời cho tài nguyên
thư viện trong thời gian tới khi các yêu cầu
mới thúc đẩy việc sử dụng big data các thư
viện hướng tới việc thu nhận tổ chức lưu trữ
dữ liệu lưu trữ vật lý trong các máy chủ hoặc
trong các cơ sở dữ liệu bảo tồn dữ liệu và
phổ biến dữ liệu làm cho dữ liệu có sẵn trong
thư viện trở nên dễ dàng tiếp cận hơn thông
qua các sản phẩm trực quan các thư viện
tiến tới xây dựng tạo lập hệ thống bảo quản
nghiên cứu trao đổi
thông tin và tư liệu 2
kỹ thuật số bảo tồn cả tài nguyên số và siêu
dữ liệu mô tả có thể phát triển trong nhiều
năm tới để đáp ứng với các yêu cầu mới
hai là cung cấp sản phẩm dịch vụ thư
viện mang tính cá nhân hóa tùy chỉnh
theo người dùng tin
hiện nay các thư viện đang có xu
hướng cung cấp nhiều tài nguyên và dịch
vụ trực tuyến nhiều thư viện đang sử dụng
các phương tiện truyền thông xã hội như
facebook instagram để quảng bá các sản
phẩm và dịch vụ thư viện các phương tiện
truyền thông xã hội này cho phép các thư
viện thu thập và sở hữu dữ liệu người dùng
thư viện cùng với các dữ liệu khảo sát thư
viện dữ liệu định tính thông qua phỏng vấn
bảng trò chuyện dữ liệu tương tác xã hội
từ các trang truyền thông xã hội các thư
viện mở rộng bộ sưu tập dữ liệu thư viện và
dựa vào các công cụ và phương pháp đánh
giá để đánh giá nhu cầu tin của người dùng
thư viện từ đó thư viện cung cấp các sản
phẩm và dịch vụ thư viện phù hợp với nhu
cầu của người dùng tuy nhiên trong thời
gian tới sự gia tăng của big data làm cho
một số tác vụ thu thập dữ liệu dễ dàng và
nhanh hơn cho phép các thư viện vượt ra
ngoài công việc đơn giản là đếm và tổng hợp
các biện pháp thống kê và bắt đầu tham gia
vào phân tích dữ liệu phức tạp như phân tích
học tập và phân tích hiệu suất nghiên cứu
trong kỷ nguyên big data không chỉ
tài nguyên dữ liệu của thư viện số hiện đại
có đặc điểm của big data mà cả dịch vụ thư
viện hiện tại cũng cần sử dụng phương pháp
big data để đổi mới big data có thể
làm thay đổi mô hình cung cấp dịch vụ thư
viện trong tương lai và vai trò của thư viện
cũng sẽ thay đổi cho phù hợp các nhà
nghiên cứu cho rằng việc ứng dụng big data
có thể tác động đến hoạt động thông tin thư
viện thông qua việc cung cấp các dịch vụ thư
viện chuyển đổi phương thức cung cấp dịch
vụ ứng dụng công nghệ thông tin hiện nay
sang phương thức gắn liền tự động hóa dịch
vụ và tích hợp các hệ thống xử lý các hỗ trợ
công nghệ đối với việc kết nối trực tiếp và
việc sử dụng big data sẽ tạo ra các lợi thế
cạnh tranh để thư viện thu hút người dùng tin
theo li shuqing jiao fusen zhang yong
xu xia các vấn đề và tiềm năng của các thư
viện số trong thời đại big data liên quan đến
dữ liệu công nghệ dịch vụ và người dùng
tin sử dụng big data hiện có và xem xét các
đặc điểm về nhu cầu của người dùng tin hiện
tại theo quan điểm của người dùng tin thư
viện có thể đưa ra các ý tưởng phương pháp
hiệu quả hơn để cải thiện các dịch vụ hiện
có trong các thư viện số đồng thời nhu
cầu cá nhân hóa của người dùng tin trong
thời đại big data tạo nên yếu tố thúc đẩy sự
phát triển của thư viện số từ dịch vụ chia sẻ
tài nguyên sang dịch vụ hướng đến người
dùng tin kim young seok cho rằng bằng
cách sử dụng các phân tích trong thời gian
thực các thư viện có thể thiết kế các dịch
vụ được cá nhân hóa cho từng người dùng
tin big data cung cấp thông tin chuyên sâu
về hành vi và thông tin cá nhân của người
dùng tin từ đó tạo ra trải nghiệm cá nhân
hóa 9 ví dụ người dùng tin tìm kiếm trên
trang opac của thư viện thì dữ liệu về những
gì người dùng tin gõ ở mục tìm kiếm tần suất
tìm kiếm số lần tham khảo danh mục tài liệu
số lần xem mô tả tài liệu được thu thập và
phân tích để tối ưu trải nghiệm tạo cơ hội lớn
để thu hút người dùng tin thông qua cá nhân
hóa đặc biệt với các công cụ phân tích dự
báo của big data thư viện sẽ nắm được thị
hiếu nhu cầu chính xác để cung cấp các sản
phẩm dịch vụ phù hợp với người dùng tin
trong thời gian thực
ba là ứng dụng dịch vụ phân tích dự báo
giống như hầu hết các ngành khác phân
tích dự báo sẽ là một sự thay đổi lớn quan
trọng trong các cơ quan thông tin thư viện
phân tích sử dụng big data làm nền tảng cho
sự phát triển của thư viện sẽ giúp thư viện
hoạt động hiệu quả hơn đồng thời làm thay
đổi căn bản mối quan hệ giữa thư viện và
người dùng tin theo cách truyền thống mối
quan hệ giữa thư viện và người dùng thư viện
khá đơn giản người dùng thư viện nộp tiền
làm thẻ thư viện và đổi lại họ được phục vụ
trong các dịch vụ khác nhau của thư viện tuy
nhiên mối quan hệ này đang dần thay đổi
nghiên cứu trao đổi
thông tin và tư liệu 2
và người dùng thư viện không chỉ đơn giản là
người sử dụng dịch vụ mà đã trở thành một
đối tác trong việc cung cấp dịch vụ của thư
viện người dùng thư viện cung cấp dữ liệu
hành vi người dùng thông qua các dữ liệu cá
nhân như lịch sử sử dụng tài liệu thư viện lịch
sử tìm kiếm cách thức thói quen tìm kiếm
các công cụ big data phân tích dữ liệu đưa
ra thông tin chi tiết xác định khuynh hướng
nhu cầu sử dụng thư viện nhu cầu tài liệu
trong hiện tại và dự đoán các hoạt động của
người dùng thư viện trong tương lai các công
cụ remarketing trên nền tảng website thư
viện hay mạng xã hội thư viện sẽ hỗ trợ các
thư viện marketing trực tiếp đến người dùng
tin các tài liệu dựa trên sở thích và dự báo nhu
cầu simovic aleksandar nhận định
các công cụ big data kết hợp với các thuật
giá trị tiềm năng của người dùng tin cá nhân
và mô hình hoạt động thư viện trong tương
lai giúp dự báo tốt hơn các vấn đề phát sinh
trong quản lý các sản phẩm và dịch vụ thư
viện để tăng cường khả năng cung cấp thông
tin tốt nhất cho người dùng tin về phía
thư viện việc sử dụng tài nguyên big data
hiện có và xem xét các đặc điểm về nhu cầu
của người dùng tin hiện tại theo quan điểm
của người dùng tin có thể đưa ra các ý tưởng
và phương pháp hiệu quả hơn để cải thiện
các dịch vụ hiện có trong thư viện kỹ thuật số
đồng thời căn cứ vào các kết quả phân tích
dự báo thư viện có thể xác định thời gian
phương thức để quảng cáo cho các sản phẩm
và dịch vụ thư viện đến người dùng thư viện
về phía người dùng thư viện dựa vào các
kết quả dự báo về hành vi tìm kiếm tra cứu
sử dụng thư viện các hệ thống khuyến nghị
recommendation engine sẽ gửi đến người
dùng tin các tài liệu có thể họ quan tâm
bốn là mở rộng dịch vụ chăm sóc
người dùng tin
dịch vụ chăm sóc người dùng tin có vai
trò quan trọng trong sự thành công của các
thư viện đặc biệt trong môi trường thư viện
điện tử thư viện số các thư viện đang cố
gắng để hiểu được người dùng thư viện giúp
họ dễ dàng liên hệ với thư viện để đáp ứng
các thắc mắc nhu cầu của mình big data
hỗ trợ các thư viện trong việc hình thành một
hệ thống chăm sóc người dùng thư viện linh
hoạt tạo ra giá trị từ quá trình xây dựng mối
quan hệ thân thiết với người dùng thư viện
cùng với big data hệ thống trả lời tự động
như chatbot không cần sự trợ giúp của
con người phát triển tương ứng giúp tăng
hiệu quả phân tích dữ liệu big data hiện
nay nhiều thư viện sử dụng chatbot để giao
tiếp trao đổi với người dùng thư viện tiếp
nhận các ý kiến cụ thể của người dùng về
sản phẩm và dịch vụ của thư viện cũng như
các nhu cầu của người dùng khi người dùng
truy cập vào website hay fanpage của thư
viện họ có rất nhiều thắc mắc và muốn được
giải đáp chatbot sẽ đưa ra các gợi ý hỗ trợ
từng bước một cung cấp thông tin về các
sản phẩm dịch vụ của thư viện cho người
dùng chatbot được thiết kế và phát triển để
vừa là nền tảng trò chuyện giữa chatbot với
người dùng vừa cung cấp các tính năng thu
thập dữ liệu người dùng thư viện từ các đoạn
đối thoại qua những dữ liệu người dùng thu
thập được công cụ phân tích dữ liệu big data
tiến hành phân tích xác định những nhu cầu
mong muốn của người dùng thư viện và từ đó
thư viện có thể đưa ra các phản hồi thích hợp
và xây dựng mối quan hệ lâu dài với người
dùng thư viện bên cạnh đó chatbot nhắc
nhở người dùng thư viện về việc sử dụng thư
viện như thời hạn trả tài liệu thời hạn đổi thẻ
thư viện hay gợi ý nhiều dịch vụ thư viện khác
mà người dùng có thể cần đến trong quá trình
sử dụng đặc biệt chatbot giúp thư viện
chủ động hỗ trợ 7 tăng trải nghiệm tối
đa cho người dùng thư viện mọi lúc chatbot
lưu lại lịch sử đối thoại thông tin người dùng
làm cơ sở cho các thư viện sử dụng phân tích
big data có thể phân tích được chính xác
các khúc mắc của người dùng thư viện và
cả những sản phẩm hay dịch vụ còn thiếu
trong chính thư viện chatbot hỗ trợ các thư
viện khai thác big data phục vụ người dùng
trong tương lai số thư viện sử dụng chatbot
để chủ động chăm sóc người dùng tin được
dự báo sẽ tăng lên nhanh chóng bởi những
tính năng và lợi ích mà chatbot mang lại
cùng với đó thông qua dữ liệu người dùng
nghiên cứu trao đổi
thông tin và tư liệu 2
các thư viện có thể phân tích dự đoán các
vấn đề có thể xảy ra trong quá trình cung cấp
các sản phẩm dịch vụ thông qua phân tích
cảm nhận của người dùng thư viện và thực
hiện các giải pháp kịp thời
có thể thấy big data giúp tối ưu hóa hoạt
động thư viện bằng việc thu thập phân tích
thông tin tăng trải nghiệm của người dùng
tin bằng cách cá nhân hóa thư viện số cùng
với đó big data có thể giúp các thư viện tiến
hành phân tích dự báo tìm ra các đặc điểm
chung dự báo thị hiếu đọc tình trạng sử dụng
thư viện của người dùng tin bằng việc kết hợp
các cơ sở dữ liệu không chỉ vậy big data tạo
dịch vụ mới dựa vào trải nghiệm của người
dùng tin trong quá trình sử dụng thư viện
tài liệu tham khảo
1 campbell d grant cowan scott r the
paradox of privacy revisiting a core library value in
an age of big data and linked data library trends
vol no 3 p
danah
crawford
critical question for big data information
communications and society
3 doug laney 3d data managment
controlling data velocity and variety
4 francis x diebold big data dynamic
factor models for macroeconomic measurement
and forecasting discussion of reichlin and
watson paper in economics and econometrics
eighth world congress of the econometric society
5 gartner survey analysis big data adoption
in shows substance behind the hype
6 gerrard d mooney j thompson d
digital preservation at big data scale proposing a
step change in preservation system architectures
library hi tech
truy cập ngày
7 howe d the future of biocuration
nature p
8 kenneth cukier data data everywhere a
special report on managing information economist
newspaper
9 kim young seok big data analysis of
public library operations and services by using the
chernoff face method journal of documentation
vol no 3 p
li shuqing jiao fúen zhang yong xu xia
problems and changes in digital libraries
in the age of big data from the perspective of user
services journal of academic librarianship vol
controlled demand paging for out of core
visualization report nas nasa ames
research center
marydee ojala big data and ai
technology transparency and trust
truy cập ngày
randal e bryant randy h katz và edward d
lazowska big data computing creating
revolutionary
breakthroughs
commerce
science and society computing community
consortium truy
cập ngày
simovic aleksandar a big data smart
library recommender system for an educational
institution library hi tech bradford vol iss
3 tr steve bryson david kenwright michael
cox david ellsworth robert haimes
visually exploring gigabyte data sets in real
communications of the acm vol no 8 tr
tan jee toon dữ liệu lớn nhân
tố thay đổi cuộc chơi của doanh nghiệp
lon nhan to thay cuoc choi cua doanh
nghiep htm truy cập ngày
waqar ahmed kanwal ameen defining
big data and measuring its associated trends in
the field of information and library management
library hi tech news p
ye chunlei research on the key
technology of big data service in library
the institude of electrical and electronics engineers
inc conference proceedings piscataway
yu jen chien library data big data or
better data challenges from the field asist
meeting proceeding of asist annual meeting
vol no 1
zhan ming widén gunilla public
libraries roles in big data the electronic library
vol no 1 p
ngày tòa soạn nhận được bài
ngày phản biện đánh giá ngày chấp
nhận đăng
nghiên cứu trao đổi",4768
big-data.pdf_0,big-data.pdf,"logistics operations with big data analytics
ishita gupta and manjunath kamath
school of industrial engineering and management
oklahoma state stillwater ok
introduction
the concept of big data has been around for many years only in the last few years have organizations
started to understand how they can use big data to gain insightful knowledge about their business operations
which is enabling them to make better business decisions while there is no single definition big data
usually works on the principles of four vs velocity variety and veracity as the name suggests
big data is really big meaning a huge amount of data is being generated daily reaching the scale of
petabytes this data comes in all forms structured semi structured and unstructured and is pouring in
from all directions and generated by many systems and devices such as transactional systems log files
gps devices smartphones rfid readers surveillance cameras sensor networks internet of things iot
and social media finally as big data becomes an important asset for enterprises the focus is also on the
trustworthiness of data and its sources
according to gartner inc big data is high high velocity and high variety information assets that
demand cost effective innovative forms of information processing for enhanced insight and decision
making a in this article we first elaborate on the big data concept and present the storage and processing
technologies that have been developed to deal with big data we then briefly discuss the evolution of
operations finally we conclude by discussing key challenges that businesses have to face as the use of
big data analytics becomes more widespread
understanding big data
regardless of the decision to be made optimized production work schedules accurate forecasts customer
preferences data nowadays has the potential to help businesses succeed more than ever before from an
existing processes by focusing on the current business needs or create products and services as new value
propositions a challenge that organizations increasingly face is finding and working with trusted data
working with inaccurate and untrusted data can be worse than having no data at all as data requirements
and regulations become more complex organizations must be aware of where all their data is coming from
where it is getting stored and who is interacting with this data as conclusions are drawn 2
what is big data
the evolution of the world wide web has redefined the kind
of data that needs to be handled and tracked the speed at
which the information is flowing into online systems and
the number of customers a company must deal with on a
environment new definitions for big data have been
proposed with a focus on technologies that handle this data
o reilly defines big data as big data is data that exceeds
the processing capacity of conventional database systems
the data is too big moves too fast and doesn t fit the
structures of traditional database architectures to gain
value from this data organizations must choose an
alternative way to process it 3
to understand how big data is transforming businesses we
need to understand its nature as most definitions of big data
focus on the size of data in storage 4 size is important but
there are other aspects to big data namely variety
and more recently veracity 2 together they are called the 4
vs of big data velocity variety and veracity
going beyond traditional data warehouses
big data is not limited to traditional storage methods where
structured data was stored and retrieved from relational
databases data warehouses and data marts 6 here the data
is uploaded to operational data stores using extract
transform and load etl tools which extract data from
internal and external sources transform the data to fit the
operational needs and finally load the data into the data
warehouse the key point is that the data is getting cleaned
transformed and cataloged before being made available for
data mining and online analytical functions this traditional
new data sources until they are cleansed and integrated
since data is ubiquitous these days big data storage
environments need to be magnetic in nature attracting
data from all sources hence big data calls for magnetic
agile and deep mad analysis skills which differs from
tools for data analysis big data storage should allow analysts to easily process and use data rapidly
nowadays for providing high query performance and platform scalability non relational databases such as
not only sql nosql were developed for storing and managing unstructured data 7 these newer
deployment they separate data management and data storage and focus on high performance scalable data
4 vs of big data
the ability to process a large
amount of information available and
produced from transactional records to
social media from internet of things to
system logs etc
velocity the rate at which data is
getting created every second of the day
with digitization being a major
contributor
being
generated and logged than ever before 5
also the rapid adoption of social
media and the internet of things has
created a deluge of data advances in
machine learning and ai have made
previously useless data much more
useful now
variety it is the diversity of data
which organizations are witnessing
companies are used to managing and
processing a limited set of data such as
transactional
records
advances in technology have enabled
the analysis of unstructured data which
includes images voice recordings
videos and texts generated from
several platforms including social
media to deliver new insight
veracity it is not just the quality of
data but also the trustworthiness of
accuracy of data is affected by
uncertainty due to inconsistencies
incompleteness ambiguities etc
database specific languages
why big data
when organizations adopt big data as a part of their business model the first tangible question is usually
what value this big data will provide to the company 7 data must be used to make better decisions to
optimize resource consumption and improve process quality and performance it should also aim to
perform precise customer segmentation optimize customer satisfaction and increase customer loyalty
new business models should be enabled with the use of big data which complement the revenue streams
from existing products and create additional revenue from new products
the new sources of big data include industries which are taking a big step step towards digitization and as
a result data growth in the past few years has been phenomenal some of the areas where data is coming
from include social media internet browsing pattern data advertising response data financial forecasts
location information driving patterns vehicle diagnostics and traffic and weather data from sensors
monitors and forecast systems other sources of data include data from healthcare where the healthcare
industry is implementing electronic medical records and digital imaging which is used for short term public
health monitoring and long term research programs similarly low cost gene sequencing can generate
hundreds of terabytes of data that must be analyzed to look for genetic variations and potential treatment
effectiveness in life sciences 8 another area is data from video surveillance which is transitioning from
cctv to iptv cameras and recording systems that many organizations want to analyze for behavioral
patterns for security and service enhancement transportation and logistics industry has been generating
and storing enormous amount of data coming from sensors gps transceivers rfid tag readers smart
meters cell phones material handling equipment enabled with sensors etc this data can be used to
optimize operations and derive operational business intelligence to realize immediate and future business
analytics and big data analytics
data analytics is the science of analyzing raw data with the purpose of drawing conclusions about
used to extract previously unknown useful valid and hidden patterns and information from large data
sets 6 while the focus of analytics has been on inference it can also provide prescriptive insights as
explained later in this section hence analytics has a significant impact on research and technology as
businesses recognize its great potential in helping them gain competitive advantage
big data analytics is the use of advanced analytic techniques against very large and diverse data sets that
include structured semi structured and unstructured data from different sources and in different sizes from
terabytes to zettabytes b it helps in uncovering hidden patterns unknown correlations market trends
customer preferences and other useful information advanced analytics can help organizations discover
what has changed and how they should react analytics is the best way to discover new customer segments
organizations are implementing specific forms of analytics tools and techniques which include data mining
statistical analysis data visualization artificial intelligence machine learning and other data capabilities
using them now as most of these techniques adapt well to very large multi petabyte data sets
big data s worth is only realized when businesses can indulge in decision making using this data to enable
such data driven decision making organizations must use efficient processes to turn the high of
fast moving and diverse data into meaningful insights analyzing big data allows researchers and businesses
moves more efficient operations higher profits and satisfied customers and an overall competitive
advantage 6 big data analytics could be viewed as a sub process in the complete process of knowledge
extraction from big data
evolution of data analytics tools
as organization began to adopt data analytics in the late 1990s and early 2000s they faced many hurdles
data was not that easily accessible as it is now and was mostly locked down and managed by it
professionals analysts used to spend more time collecting and preparing data than analyzing it they
focused on finding more accurate and reliable solutions to business problems while keeping the solutions
simple at the same time so that business users could understand it some examples of tools used during
this time period are sas a tool for building backend data inference and modeling oracle and teradata
detailed solution suites for easy development of solutions ibm cplex a tool for solving large
optimization problems and cognos and microstrategy tools for visualization mostly in the form of
reports
in late 2000s social media giants like google and facebook and other internet based companies in general
started uncovering collecting and analyzing newer types of data which later evolved into big data in
addition to the data generated by companies in their internal operations and transactions newer data was
brought in from external sources including public data sources social media and mobile devices analysts
realized this new data was qualitatively different e g unstructured text pictures audio and video along
tools and technologies examples of which are hadoop a pioneer in distributed data storage and processing
with low cost flexibility and scalability python and r open source programming languages with vast and
ever evolving libraries for statistical data analysis tableau looker and microsoft power bi popular
descriptive predictive and prescriptive analytics
analyzing data is not limited to deriving insights from the past but it can also help businesses in predicting
future outcomes and optimizing business performance currently organizations use three types of analytics
at different stages in their decision making process descriptive predictive and prescriptive analytics as
shown in figure 1 the latter two are also referred to collectively as advanced analytics
descriptive analytics does exactly as the name suggests describe or summarize the data and convert it
into something useful it is the most basic type of analytics and almost of the organizations today use
this technique descriptive analytics is the analysis of historical data using data aggregation or data mining
and lies at the bottom of the big data analytics value chain however it is extremely valuable because it
provides insight into past behaviors which can help in understanding how several factors can influence the
organization s future
descriptive analytics is an important step to make raw data understandable to its users and it helps in
web servers using google analytics tools namely page views it can be used to determine if a strategy was
a success or not the main objective in descriptive analytics is to find the reasons behind the previous
performance patterns of the organization and to identify and address areas of weakness and strength so that
it can help the organization in strategizing
the majority of the statistics we use comes from descriptive analytics e g calculations as simple as
averages and standard deviations descriptive models use basic mathematical and statistical techniques to
derive key performance indicators that can highlight the historical trends in data stata ms excel and
spss represent the older generation of descriptive analytics tools while r and python are quickly becoming
the preferred tools in industry because of vast open source libraries and the ease of development and
deployment descriptive analytics can yield historical insights into an organization s production inventory
levels sales operations financials and customer behavior
figure 1 analytics framework by tom davenport26
of future outcomes it is one of the more sophisticated types of analytics techniques and employs statistical
techniques and machine learning it is used to detect clusters tendencies and exceptions and to predict
future trends making it a valuable tool for forecasting the foundation of predictive analytics is probability
it takes the data which the user has and tries to fill in the missing data values with best guesses it helps in
complex forecasting in marketing and sales this helps an organization to set realistic goals for business
restrain expectations and do effective planning
used tools are sas matlab r python among others the common functionality of these tools is that
they combine historical data found in pos erp crm and hr systems to identify patterns in the data and
clustering for identifying clusters finally simulation can be employed to statistically predict the outcomes
of specific decision scenarios
determine the probability of customer making timely payments other business uses include how sales
might close at the end of a year inventory level forecasts predicting what items a customer might purchase
together and other customer purchasing patterns despite all the advantages that predictive analytics brings
to the table it is important to understand that forecasting is just an estimation and its accuracy depends on
the quality and stability of data
techniques to explore a given set of options and prescribe the best possible solution for a given scenario
employing neural networks where optimization models are used to determine coefficients or weights of
neurons using training data sets once trained the neural network model can suggest the optimal course of
but also determines what the company should do it provides recommendations for the actions to be
taken to achieve optimal business performance because it has power to suggest optimal solutions
prescriptive analytics is the ultimate frontier for advanced analytics
prescriptive analytical models are complex in nature however when implemented efficiently prescriptive
analytics can have a significant impact on the decision making effectiveness of the organization technical
advancements such as cloud computing have made deployment of these complex models much easier
companies which have access to analytics experts and the powerful computing resources needed are using
experience and to make sure that the right product is being delivered at the right time airline systems use
sophisticated prescriptive models for optimal seat inventory allocation for a given price structure based on
travel factors demand levels purchasing patterns timings etc in order to maximize the revenue generated
increasing number of organizations are realizing that big data analytics gives a competitive advantage and
hence they are ensuring to choose the right kind of analytics solutions to reduce operational cost enhance
service quality and increase roi
and devices such as pos erp scm rfid gps blogs and wiki entries not to mention the unlimited
data generated from sources like cctvs digital clickstreams imagery social media posts and discussions
chain such as sensors smart devices and tags are continuously gathering real time data and providing an
this data to make insightful decisions which could help boost productivity and reduce costs
company
technique technology
system
impact
performance and ability to provide services
immersive design center
achieved product excellence reduction in time to
market through co development and co production
customers
lennox
international
integrated forecasting
system
better service level accurate prediction of customer
needs and demand automated planning and
forecasting operations
walmart
data café
inventory management with streaming analytics real
time data delivery and updates every few hours and
accurate performance analysis of each store
groupe
danone
machine learning based
planning system
improved forecasts and sales with better prediction
accuracy and greater profit margins
granarolo
machine learning
accurate forecasts reduction in delivery time by
upto and better service levels
levi strauss
iot and predictive
using intel s trusted
analytics platform
better tracking of in store items using rfid tags
updating item location and inventory helping
salesperson track misplaced item to avoid lost sales
morrisons
data intensive
forecasting method
increase in forcasting accuracy reduced inventory
stockouts and obsolescence better access to
company s logistics needs
orders packed and pushed into logistics network
before actual customer orders
flexible automation
robots bring items from storage locations to picking
and packing area
drone based delivery
goods delivered to locations less than minutes
away from an amazon warehouse
cloud based 3d
warehouse layout
planning
improve storage efficency and picking productivity
of an exiting warehouse by simulating new
configurations
camera guided agvs
and tracking
optimize picking accuracy inventory turns and
warehouse productivity in real time using inputs
from sensors such as shelf weight and weight on
forklift
quality early warning
system
reduced rework increased productivity and cost
savings higher quality standards and improved
service levels by detecting and prioritizing quality
buying analysis tool
distribution channel management better service level
and improved inventory management
accounts receivable tool optimized the resources needed for revenue
collection
merchandise
warehouse
real time monitoring and
tracking
greater visibility for customers better pallet
management optimized space utilization greater
labor productivity inventory accuracy of 9 and
improved customer satisfaction
orion
optimized delivery routes in north america
saving close to million annually reducton in
cost and emissions by selecting the right mode of
transportation
smarttruck
optimized initial route planning based on incoming
shipment information reduction in mileage and cost
and improved co2 efficiency
resilience
accuracy in risk detection prevent production
inefficiencies and revenue losses maintain service
levels and reduce emergency cost by efficiently re
routing shipments in case of unforeseen events
geovista
a tool for small and medium scale industries to
information provides realistic forecast of competitors
in a given location
address management
improves shipment delivery accuracy in areas where
quality of address information is poor real time
ddress verification to optimize route planning
logistics
raytheon
manufacturing
amazon
logivations
retail
warehouses
raytheon a major u s based defense contractor and industrial corporation made use of data analytics to
program which integrated structured and unstructured data from internal and external sources with more
ability to provide services in the face of disruptive events raytheon was able to immediately identify if a
and programs to achieve cost reductions raytheon has also developed smart factories which have the
capacity to handle big data coming from different sources like sensors instruments cad models internet
transactions simulations and digital records in the company which equips them with real time control of
various elements of the production processes for example their immersive design center idc makes
use of a 3 d immersive environment to achieve product excellence and decrease time to market through
co development and co production of products by immersive data visualization and interaction this also
the design and detect potential problems without the work and rework associated with expensive prototypes
resulting in reduced costs
lennox international a u s based cooling and heating devices manufacturing company integrated
machine learning into its forecasting system to ultimately improve customer satisfaction while coping with
their expansion throughout north america with the help of machine learning algorithms they accurately
predicted customer needs while understanding customer demand better it also helped the company to
automate its planning and forecasting operations
example a pharmaceutical company created a database of all the bids submitted for packaging this data
new packaging another example is how iot with its network of sensors embedded in millions of devices
plant engineer for replacing the faulty or near faulty part it also helps in determining when and how
critical maintenance is required by a specific machine thereby avoiding costly equipment breakdowns and
improving the overall production efficiency
daily production needs to be monitored to maintain the efficiency and output of a company big data
analytics uses the data collected from operational machines employee records and data logs of the number
of units produced to provide insights to the operations manager helping him her to make changes that are
profitable for the company manufacturers are also exploring predictive analytics to realize significant
savings in product testing and improving product quality since different products and parts require
different tests instead of performing numerous quality tests on each part data mining and pattern
recognition can be used to determine the type and number of tests truly needed for each part or product
real time data feeds to its decision makers walmart s data café based at their bentonville arkansas
headquarters takes care of most of this cloud architecture their original data infrastructure only enabled
managers to get weekly reports which prevented them from making decisions based on real time market
conditions also the reports were standardized with little room for customization data café which was
built on sap s hana in memory analytics engine enabled inventory management with streaming
analytics and provided an enterprise view of timely information flow for a large cross sectional staff
and updated every few hours furthermore the system was designed to be responsive to providing reports
and queries required by managers in the given time frame which helped them gain timely insight and make
better decisions these insights are derived from streams of internal and external data which includes
petabytes of recent transactional data and can be manipulated modeled and visualized the
importance of near real time insights is crucial since it helps managers respond to challenges in real time
as they arise for example on black friday walmart s data café provides near real time insights on the
performance of east coast stores which enables walmart to make pricing adjustments for west coast stores
before they open during a recent halloween sales analysts were able to see that two stores were not
selling a novelty cookie that was very popular in most stores using near real time data from data café it
was discovered that simple stocking oversight led to the cookies not being put on shelves in these stores
the company was able to react in real time to avoid additional lost sales data café also provides automated
alerts to managers when a metric falls below a threshold in a department this tool has reduced the problem
solving time from weeks to minutes using reliable internal and external sources of data
its customers by helping them find the product they want and avoids missing sales by locating misplaced
items using iot technology coupled with advanced analytics levi s in collaboration with intel
implemented a solution using intel s trusted analytics platform tap which helped salespersons to
items in store antenna sensors installed in the ceiling of the store to continuously track the rfid tags and
a gateway system located in the store to collect data from these sensors and send smaller data sets to a
cloud based analytical tool built on tap for detailed analysis this technology helped determine when
items are no longer in their correct place or no longer available at that time tap algorithms use data
collected overnight to determine the exact location of various groups of items and during store hours
sensors track the location of items and an algorithm determines if an item is in its assigned location if an
jeans is lying in the t shirt section or left in the fitting room the tap algorithm will generate an alert on
the salesperson to keep the item where it belongs and avoid lost sales levi s also aims to generate customer
insight using big data analytics with the data collected from sensors tracking customers in store behavior
to better understand their preferences
groupe danone a french multinational food product corporation found itself making accurate predictions
only percent of the time for responses to promotional offers which was resulting in significant losses to
the company when they implemented machine learning in their planning architecture they saw
significant improvement in both sales and forecasting similarly granarolo an italian dairy company used
machine learning to increase its forecasting accuracy by 5 percent decreased delivery times by up to
percent of the original time which resulted in better service levels morrisons one of uk s largest food
retailers was able to dramatically improve same store sales and achieve a reduction in shelf gap and
a 2 to 3 day reduction in store inventory by implementing a demand forecast and replenishment solution
from blue yonder which uses ai technology to improve demand planning and reinvigorate replenishment
based on customer behavior in every store blue yonder s data intensive forecasting methods deployed
as cloud based services is making such advanced capabilities accessible to other retailer s as well
it is now possible to re envision the planning processes by using external and internal data sources to make
real time decisions based on market trends uncertainty seasonality and other fluctuations
operations they have used various analytical tools to solve a range of problems and a few of them are
discussed here ibm s quality early warning system qews was typically deployed upstream at
chain ibm was able to reduce rework increase productivity ensure higher quality standards and improve
customer satisfaction leading to significant cost savings for a company like ibm ensuring correct
inventory levels with so many business partners was challenging they made use of ibm buying analysis
management delivery of the right product at the right time to meet customer demand while maintaining
proper inventory levels ibm also used a tool named accounts receivable which uses advanced analytics
an innovative way to use social media to monitor channels and provide valuable data on events which may
several years
help in warehouse design optimization and in improving storage efficiency and picking productivity of an
existing warehouse by simulating new configurations another example is the analysis of images and videos
captured by agvs and sensor inputs including shelf weight and weight on the forklift to monitor picking
accuracy inventory turns and warehouse productivity in real time also forklift drive picking
productivity and route optimization can be achieved by analyzing the route choices and driving behaviors
be used as a big data hub collecting real time data to identify additional sources of waste in the warehouse
operations using a hybrid of analytics and erp and wms data amazon is another warehouse automation
pioneer deploying kiva robots that bring the items racks to the picking and packing area in their
fulfillment centers with increasing pressure to reduce order to delivery times warehouses are turning to a
flexible automation strategy by using autonomous technologies such as amazon s kivac robots and
greyorange s butlerd system to increase their picking efficiency amazon has also tried to deliver goods
to people living less than minutes away from an amazon warehouse or distribution center via a drone
packed and pushed into the logistics network before the actual customer orders are placed
merchandise warehouse co mw a logistics provider of multi temperature warehouse services in the us
mid west provides services such as tempering inspection blast freezing temperature monitoring labeling
import export and packaging with such operations there is little room for error since clients food
products could get spoiled if they are not maintained at correct temperatures mw needed real time
information technology which would help them track the state of items in its warehouses at all times and
enable quality assurance with comprehensive traceability they wanted this for all operations including
inspections and holds technologies such as cctv wms electronic data interchange mobile
computers and scanners were employed to help track and analyze data to get real time information in the
warehouse and manage inventory it helped mw s customers gain visibility by having on line access to
temperatures activity reports and information about inventory levels mw s solution also includes tools
for pallet management for tracing every pallet from the time it arrives in the warehouse to until it leaves
special functionalities for cold storage such as temperature reading and recording and the ability to restrict
inventory to marked temperature zones were provided by the new system it also ensures greater labor
productivity and accuracy using workflow based warehouse management and could automate processes
designed for specific customer needs mw reaped various other benefits from this initiative like accurately
capturing billing events in real time resulting in reduced labor used for billing and paperwork the system
helped the company deal with the of catch weight where the actual weight of the product especially
meat varies when it hits the retail shelves a common problem in cold storage warehouses and food
industry increased customer satisfaction levels were also achieved since clients had real time access to
information and reports when needed the solution helped mw achieve an inventory accuracy of 9
percent from a previous 6 percent
logistics companies need to keep the goods moving at all times even in the face of disruptions such as
storms cargos getting stranded due to ship crashes and geopolitical events in order to keep the businesses
running a netherlands based logistics management company uses big data analytics on microsoft s azure
cloud to keep its customers informed about the number of goods in each container their location at a given
challenges which could delay the delivery of an order tariff calculations and fees related to the movement
conjunction with microsoft cloud technologies to combine and analyze data coming from news feeds and
identify a challenge and develop a solution to address it could be anywhere from 3 to 9 months with the
use of big data technologies this time has been brought down to a couple of weeks depending upon how
complex the problem is
manage a massive flow of freight goods and products daily while at the same time creating vast data sets
millions of shipments are tracked daily from origins to destinations generating information such as the
content weight size location and route of each individual shipment across a large number of networks
companies are exploiting and analyzing these large data sets to improve their operational efficiencies
quality logistics companies can utilize big data analytics to consolidate interpret and store the data
coming from various sources for immediate or future use based on their requirements
courier and delivery companies like ups use real time routing of deliveries using the trucks geo location
and traffic information data ups spent almost years developing its on road integrated optimization
and navigation system orion to optimize close to routes in north america in its delivery
network this system saves the company million to million annually by saving about
million miles per year which is a reduction of million gallons of fuel consumed and reducing co2
emissions by almost metric tons data mining techniques also help logistics companies deliver
services with fewer delivery attempts by using predictive analytics to predict when a customer is more
likely to be available at home costs and carbon emissions can also be reduced by selecting the right mode
of shipments and determine which ones need immediate air or truck deliveries and which still have time
and can be delivered by rail
better transportation planning can be achieved with the use of transportation management system tms
helping logistics providers make real time decisions which result in reduced costs greater reliability and
improved customer satisfaction for example data streams produced by sensors on delivery trucks beacons
which broadcast their presence to nearby devices such as computers and smartphones radar devices and
iot help a company determine the likelihood of a shipment arriving on time or getting delayed by
employing simulation models when a shipment is going to be late a carrier can make real time
and is currently employing several smart systems around their services increasing the last mile efficiencies
achieve real time optimization of delivery routes where streams of data are processed to maximize the
optimization on the last mile saving time in the delivery process when the vehicles are loaded and
unloaded manual sequencing of shipments is eliminated by the use of sensors and dynamic calculations
are used to find the optimal delivery sequence based on real time traffic conditions on the road telematic
databases are used to change the delivery route automatically dhl s smarttruck uses data mining
machine learning and other data analytics techniques to optimize the initial tour planning based on
incoming shipment on a daily basis dynamic routing system recalculates the routes depending on the
traffic situations and delivery times this also results in cost reduction and improved co2 efficiency by
reducing the miles travelled
world apart from being flexible and resilient businesses need accurate risk detection systems to keep
running smoothly big data analytics and complex event processing algorithms are used to alert businesses
when a pattern falls in the set of critical conditions such as tornadoes or floods in an area or breakdown of
fleet these alert systems send a report on the probability and impact of the risk and provide suitable
actionable insight to alleviate potential interruption with this information on hand customers can re route
designed to maintain prescribed service levels protect sales and operations and reduce emergency costs
creating a competitive advantage for the company
future economic development is often modeled on global transportation of goods and services the type of
analytics tools to extract detailed microeconomics insights from data generated by millions of daily
shipments by their distribution networks these shipment records are a valuable resource for market
intelligence research and logistics providers refine this data to substantiate existing market research
shipment records and market research outcomes the primary target group for these advanced data analytics
services are small and medium sized enterprises which lack capacity to conduct their own market research
the results from regression based analytics have high predictive value which can help these enterprises
serve a larger customer base and generate accurate forecasts based on industry geography and product
category dhl geovista is one such online geo marketing tool available for small and medium sized
dhl address management system is another useful tool making use of big data techniques to deliver
shipments more accurately customer s delivery address verification is a fundamental requirement for
any logistics provider this can be troublesome in developing countries and other remote areas where the
quality of address is usually poor due to lack of structured naming schemes for streets and buildings in an
area address management uses daily freight and parcel delivery data and matches this data with reference
data and returns the incorrect incoming data with validated data from the database in order to verify the
address in real time and optimize route planning for retailers and public sector entities
locating a new store is a strategic decision for a company and big data analytics could play an important
role here extensive data analysis is performed by the analysts in exploring customer data demographic
factors retailer network location of other competitors in the area and market potential a recent example
of this is the location for amazon s hq2 visualizing the growth of a company has become easier with the
use of data analytics since it is now possible to quickly compare the performance matrix of different sites
and identify the reasons behind such results predictive analytics comes in handy in analyzing the market
and gaining insight on questions related to global growth strategy site relocation new product introduction
price optimization is crucial for a company as having the right price for both customer and retailer keeps a
business profitable data analytics tools simplify the process of price formation which not only accounts
for the cost of production of an item but also the spending capacity of the customers and presence of
competitors in the market price flexibility buying patterns of the customers competitors prices and
seasonality are analyzed using the data coming from various sources machine learning algorithms help
identify the costs which meet the business standard by using customer segmentation to record the responses
to changes in prices furthermore using real time price optimization techniques retailers can attract new
customers and retain existing customers by adjusting the price as per market trends recommendation
engines is another great way of predicting customers behavior since they give a retailer insight into
customers reviews and opinions it also helps the retailers to increase sales and stay abreast with trends
based on machine learning algorithms recommendation engines make adjustments depending on customer
collaborative or content based data filtering is used in this process to gain useful insight which gives
leverage to retailers on customers opinions
big data challenges
companies often fail to understand what big data is its benefits and more importantly the computing and
the human infrastructure required to realize its true potential without a clear understanding of the concept
of big data adopting and implementing a project using big data tools can seriously challenge its success
we can say that handling big data is complex and companies should identify what they aim to achieve when
they de to invest in technologies using big data
the first challenge that a company is likely to face is making sense of the complex big data landscape and
reducing their dependence on legacy systems even though the industry is shifting its focus to the digital
age with adoption of iot and artificial intelligence it is still a long way before the full potential of big data
is realized industry has to develop an awareness of the various elements of the big data landscape which
include sensors to social media that collect data in memory to cloud for data storage data mining to deep
learning to convert data into useful business insights or actions any new business solution will involve a
combination of these elements and the role of people in the resulting work system is likely to change
significantly most people are resistant to change and it shows in companies when workers stick to to an
old way of thinking and doing work an example is the use of excel which to the present day remains one
of the popular tools in many companies despite having many limitations when compared to newer tools
while there is a need to educate industry to change this legacy mentality there is no need for an abrupt or
complete shift to newer tools a viable option is to slowly augment existing systems with big data analytics
tools and capabilities
with the phenomenal increase in the size of data the problem of storage space for big data has become a
real problem for many companies cloud storage is soon becoming the only viable alternative with the ever
increasing need for storage space with the maturity of the cloud computing infrastructure which includes
infrastructure for most of their computing needs but transitioning from the traditional in house computing
infrastructure to the cloud infrastructure has its own challenges according to mcafee most organizations
system before moving to the cloud for the most part cloud is cost effective compared to building and
running an it infrastructure however a company needs to carefully evaluate the cost factor based on their
academic institutions have begun to address the need for skilled professionals in the field of big data
analytics with specialized ms degrees in data science these degree programs are housed mostly in
business schools or computer science departments engineering schools to a large extent are still lagging
in providing adequate training in data science to their graduates data science professionals can manage
several new technologies such as the nosql data management framework hadoop cloud computing and
in memory analytics their skills are vital for the rapidly changing computing landscape given that
engineering schools are still looking for the right curriculum mix e g minors degree options and
certificates to train engineers in data science training employees at entry level is a challenging and
expensive proposition for companies dealing with these newer technologies when industry hires data
science professionals akin to software developers and programmers they need guidance from subject
matter experts smes to build the right tools and techniques that can help industry harness the power of
big data in the long run industry needs to quickly educate smes to understand the big data analytics
capabilities and empower them to develop big data strategies working alongside with the data science
professionals
as seen in recent times data privacy has become one of the major concerns of organizations with recent
data from multiple sources as it may compromise an individual s privacy also with an increase in the
number of connected devices within the industry data security has also become a big concern and presently
this risk is greater than ever big data analysis uses huge amounts of data for analysis and mining purposes
to reach some meaningful conclusion and security of this big data can be enhanced by using techniques
with newer secure technologies such as blockchain and data cleanroom it is possible to achieve both
partners that is completely secure from external access and where each partner can de the level of
visibility to their data blockchain a decentralized distributed database is one of the most secure options
overlooked challenge is the ethical use of data the legal infrastructure has not kept up with the rapid
development in technology which is able to collect and store vast amounts of consumer data with or without
their knowledge while it may be legal certain use of the data may be considered unethical such actions
may have a negative impact on a company as today s consumers are more educated and have experienced
negative consequences of such unethical usage
these employees need a good understanding of the business to provide solid advice resistance to
change and lack of access to data across disparate systems were the second and third biggest barriers
this results in difficulties in reconciling data from multiple sources and its subsequent analysis to gain
useful insights
the way forward
should start with a specific or narrowly defined set of objectives rather than a build it and they will come
focus the initial business case for big data analytics on customer centric objectives 7 the various
analytics whatever be the area it is desirable that the pilot project address a problem tied to a specific
business outcome the pilot project should not only help solve a business problem but also demonstrate
the effectiveness of big data analytics for the organization and its stakeholders finally for successful big
data initiatives it is essential to have strong committed sponsorship and alignment between the business
and analytics strategies 7 in the early stages of adoption the sponsor could be the cio and then shifting to
to benefit from big data analytics companies must also establish a data driven decision making culture
which calls for acting on insights from data rather than on pure managerial intuition promotion of data
sharing practices increased availability of training in data analytics and communication of the benefits of
data driven decision making are some of the strategies for promoting a data drive culture 7 while workforce
training needs to focus on improving technological and digital proficiency the future work environment
also demands training in certain soft skills the work environment is changing with the rapid introduction
of ai automation and analytics driven solutions workers need to be open to new ways of working and
have openness to agility adaptability and working in teams to cope with a constantly changing external
environment in the long run big data needs to become an integral part of the organization s operating
model there also needs to be clear ownership for big data in the organization with leadership positions
such as a chief analytics officer data science should become another established skill in the organization
acknowledgements
we would like express our gratitude to william ferrell for his constant assistance and encouragement
guidance and feedback during the formative stages of this effort we would also like to thank john
ashodian john hill ying tat leung juan ma hari padmanabhan and john paxton for carefully reading
an earlier version of this white paper and providing several constructive suggestions and feedback which
have helped us greatly improve the quality of the white paper
references
management findings from a delphi study proceedings of the 50th hawaii international conference
on system sciences
2 ibm corporation the path to data veracity ibm big data and analytics hub may
3 datastax corporation big data beyond the hype october
4 phillip russom big data analytics tdwi research
analytics aspx tc page0 m dxc technology company five industries where big data is making a difference november
five_industries_where_big_data_is_making_a_difference 4aa5 6292enw pdf
6 nada elgendy and ahmed elragal big data analytics a literature review paper in perner p
computer science vol springer cham
3 8_16
communications of the association for information systems article
8 richard l villars carl w olofson and matthew eastwood big data what it is and why you
should care international data corporation
between and insights to industries computers and industrial engineering
landscape part 1 february
lorenzo romano big data analytics a key ingredient for agility in manufacturing may
joe mckendrick walmart s gigantic private cloud for real time inventory control january
real time data
rt insights team levi s real time tracking of jeans rfid in retail april
jda store replenishment at morrisons
morrisons case study
logivation
rt insights team using mobile device for a real time warehouse
industry
third party logistics study
leadership 2017stateoflogisticsreport_new ashx
ups orion backgrounder
s id data driven logistics the growing use of predictive analytics july
data driven logistics the growing use of predictive analytics
martin jeske moritz grüner and frank weiß big data in logistics a dhl perspective on how
to move beyond the hype december
mckinsey company big data analytics and the future of marketing and sales march
20insights ebook 20big 20data 20analytics 20and 20the 20future 20of 20marketing 20sal
es big data ebook ashx
gurobi optimization the power of analytics accessed september 8
transmetrics big data and big roadblocks how the logistics industry can overcome its big
data challenges march
challenges
andrew mcafee what every ceo needs to know about the cloud harvard business review
bharat bhargava rohit ranchal and lotfi ben othmane secure information sharing in digital
david meer a call to action on big data forbes october",7790
KimAnh-HTKhoa.pdf_0,KimAnh-HTKhoa.pdf,"stats and for this publication at
tích hợp big data và điện toán đám mây động lực thúc đẩy thay đổi cho
doanh nghiệp
publications 2
on june
the user has requested enhancement of the downloaded file
8 ths ngô văn công bằng trưởng bộ môn thud
9 ths trương nhã bình trưởng bộ môn toán
1 ks phạm hữu kỳ giảng viên khoa cntt
công nghệ thông tin đã và đang là yếu tố cốt lõi thúc đẩy nền kinh tế xã hội phát triển
mạnh mẽ đặc biệt trong thời đại kỹ thuật số ngày nay sự bùng nổ của các công nghệ mới
và ứng dụng tiên tiến đã thay đổi cách chúng ta sống làm việc và tương tác với mục đích
tạo ra một diễn đàn để các nhà nghiên cứu học giả giảng viên cũng như các chuyên gia
trao đổi kết quả nghiên cứu chia sẻ kiến thức thảo luận quan điểm ý tưởng về các xu
hướng mới nhất trong lĩnh vực công nghệ thông tin và ứng dụng khoa công nghệ thông
với chủ đề khoa cntt năm
không chỉ nhằm mục đích nâng cao năng lực nghiên cứu mà còn thúc đẩy các
phát minh đổi mới và chuyển giao công nghệ trong lĩnh vực công nghệ thông tin đây là
cơ hội để các chuyên gia đầu ngành nhà nghiên cứu giảng viên và sinh viên gặp gỡ học
hỏi và hợp tác cùng nhau phát triển và ứng dụng các thành tựu kỹ thuật vào thực
tiễn qua đó mong muốn góp phần nâng cao chất lượng giáo dục nghiên cứu và
thực hành trong lĩnh vực công nghệ thông tin
do thời gian chuẩn bị có hạn việc biên tập này không tránh khỏi những thiếu
sót rất mong ý kiến đóng góp cũng như sự lượng thứ từ quý độc giả để các
kỳ sau được tổ chức ngày một tốt hơn hiệu quả hơn
trân trọng
tp hồ chí minh tháng 6 năm
mọi ý kiến đóng góp xin vui lòng gửi về
điện biên phủ p q bình thạnh tp hcm
mục lục
tối ưu hóa truy vấn trong sql server phương pháp và ứng
dụng trang 1
năng lực thực hiện bài kiểm tra giữa kì môn xác suất thống
kê của công cụ chatgpt trang
ransomware mối đe dọa trong thời đại số trang
phát hiện xâm nhập hệ thống mạng sử dụng bộ luật dựa trên
chữ ký trang
tích hợp big data và điện toán đám mây động lực thúc đẩy
thay đổi cho doanh nghiệp trang
vận dụng kỹ năng chuyên môn để xây dựng thương hiệu cá
nhân cho sinh viên ngành thiết kế đồ họa trang
ứng dụng bài toán vận tải tối ưu chi phí thu gom rác sinh
hoạt của các bệnh viện trang
những tác động của công nghệ di động đến hoạt động kinh
doanh của doanh nghiệp trang
sáng tạo nội dung ai cách mạng hóa tương lai của tiếp thị nội
dung trang
trang
tích hợp big data và điện toán đám mây động lực
thúc đẩy thay đổi cho doanh nghiệp
integration of big data and cloud computing a
driving force for business transformation
võ thị kim anh1
tóm tắt kỷ nguyên số mang đến sự bùng nổ dữ liệu tạo ra cả thách thức và cơ hội cho doanh nghiệp
sự hội tụ của big data và điện toán đám mây nổi lên như giải pháp mạnh mẽ cách mạng hóa cách
thức xử lý và khai thác dữ liệu bài viết này khám phá tác động biến đổi của sự kết hợp này đồng thời
đề xuất những cân nhắc thực tế cho doanh nghiệp bắt đầu áp dụng big data trên nền tảng đám mây
từ khóa kỷ nguyên số big data điện toán đám mây biến đổi doanh nghiệp
the digital era has ushered in an unprecedented surge of data presenting both challenges
powerful solution revolutionizing the way data is processed and harnessed this paper delves into the
transformative impact of this integration and outlines practical considerations for businesses
embarking on their big data on cloud journey
key words digital era big data cloud computing transformation business
1 sự kết hợp mạnh mẽ giữa big data và
điện toán đám mây
kỷ nguyên số đánh dấu sự bùng nổ dữ
liệu mang đến cả thách thức và cơ hội cho
doanh nghiệp khái niệm big data với đặc
trưng khối lượng tốc độ và sự đa dạng lần
đầu tiên được giới thiệu bởi laney 1
đã mở ra một chân trời mới trong việc quản lý
và khai thác thông tin tuy nhiên việc quản
lý và trích xuất hiệu quả thông tin chi tiết từ
đại dương dữ liệu khổng lồ này đã được chứng
minh là rất phức tạp
sự xuất hiện của điện toán đám mây 2
như một bản giao hưởng hoàn hảo cho big
data cung cấp giải pháp mạnh mẽ để giải
quyết thách thức này điện toán đám mây
mang đến quyền truy cập theo yêu cầu vào các
tài nguyên điện toán có thể mở rộng qua
internet giúp doanh nghiệp tận dụng tối đa
sức mạnh của big data một cách hiệu quả và
linh hoạt
trang
lợi ích của việc kết hợp big data và điện
toán đám mây được các học giả như
dikaiakos et al 3 nhấn mạnh về khả
năng mở rộng hiệu quả chi phí và khả năng
truy cập
đối với khả năng mở rộng cơ sở hạ tầng
đám mây tự động mở rộng lên hoặc xuống dựa
trên nhu cầu xử lý loại bỏ nhu cầu đầu tư ban
đầu tốn kém vào phần cứng doanh nghiệp chỉ
cần trả tiền cho các tài nguyên họ sử dụng tối
ưu hóa chi tiêu cho cntt và tối đa hóa lợi
tức đầu tư 3
về hiệu quả về chi phí doanh nghiệp chỉ
trả tiền cho các tài nguyên họ sử dụng tối ưu
hóa chi tiêu cho cntt và tối đa hóa lợi tức
đầu tư 3
còn đối với khả năng truy cập các giải
pháp big data dựa trên đám mây cung cấp khả
năng truy cập mọi lúc mọi nơi thúc đẩy cộng
tác và sự linh hoạt
sự kết hợp giữa big data và điện toán
đám mây mở ra cơ hội to lớn cho doanh
nghiệp trong việc nâng cao hiệu quả hoạt
động phát triển sản phẩm mới gia tăng lợi thế
cạnh tranh và thích ứng với môi trường kinh
doanh đầy biến động xem thống kê bảng 1
bảng 1 lợi ích của big data và điện toán đám mây
lợi ích
mô tả
khả năng mở rộng
tự động mở rộng thu hẹp tài nguyên tối ưu hóa chi phí
hiệu quả chi phí
chỉ trả tiền cho tài nguyên sử dụng
khả năng truy cập
truy cập mọi lúc mọi nơi thúc đẩy cộng tác
nâng cao hiệu quả hoạt động
tự động hóa quy trình cải thiện ra quyết định tối ưu hóa
chuỗi cung ứng
phát triển sản phẩm mới
xác định xu hướng thị trường và nhu cầu khách hàng
gia tăng lợi thế cạnh tranh
đưa ra quyết định sáng suốt và nhanh chóng dựa trên dữ liệu
thích ứng với môi trường kinh doanh
biến động
phân tích dữ liệu để dự đoán rủi ro và nắm bắt cơ hội mới
trang ứng dụng thực tiễn của big data
phân tích trong lĩnh vực big data đang tạo
ra tác động to lớn đến nhiều lĩnh vực trong thế
giới thực các doanh nghiệp đang tận dụng
sức mạnh của các giải pháp big data dựa trên
nền tảng đám mây để nâng cao hiệu quả hoạt
động phát triển sản phẩm mới và gia tăng lợi
thế cạnh tranh dưới đây là một số ví dụ cụ
trước tiên đó là ở ngành bán lẻ các gã
khổng lồ như amazon và walmart sử dụng
nền tảng đám mây để quản lý hàng tồn kho
cá nhân hóa chiến dịch tiếp thị và thu thập
thông tin chi tiết về khách hàng 4 ví dụ câu
chuyện về amazon retail
là nhà bán
lẻ trực tuyến lớn nhất thế giới tạo ra rất nhiều dữ liệu trước
đây họ đã sử dụng cơ sở dữ liệu oracle để lưu
trữ dữ liệu đó phát
triển lớn hơn kích thước cơ sở dữ liệu oracle
của họ tiếp tục tăng lên và điều này khiến việc
sao lưu cơ sở dữ liệu oracle lưu trữ trở nên vô
cùng khó khăn điều này khiến họ phải cân
nhắc đến các dịch vụ điện toán đám mây của
aws bằng cách chuyển sang aws họ đã
trải nghiệm cải thiện hiệu suất gấp lần và
giảm thời gian khôi phục từ khoảng giờ
xuống 2 5 giờ đã vượt
qua chi phí cao hiệu suất chậm và quản lý tốn
nhiều nhân công của các bản sao lưu băng
truyền thống bằng cách chuyển sang đám mây
aws họ tận dụng amazon s3 vì tính tiết
kiệm chi phí khả năng mở rộng bảo mật và
lưu trữ bền vững giúp sao lưu và khôi phục
nhanh hơn đáng kể ngoài ra việc di chuyển
các máy chủ web sang các phiên bản ec2 và
thiết lập các kết nối chuyên dụng thông qua
aws direct connect đảm bảo hoạt động liền
mạch nhìn chung việc chuyển sang aws
giúp giảm chi phí cải thiện hiệu quả và cung
cấp khả năng mở rộng cần thiết để hỗ trợ sự
phát triển của amazon bảng 3 4
trong ngành chăm sóc sức khỏe ngành
chăm sóc sức khỏe đang biến đổi nhờ vào big
data nghiên cứu của 5 cho thấy các tổ chức
chăm sóc sức khỏe sử dụng điện toán đám
mây để phân tích dữ liệu bệnh nhân từ đó cải
thiện chất lượng chăm sóc và thúc đẩy các
sáng kiến nghiên cứu ví dụ mayo clinic sử
dụng big data để phát triển các phương pháp
điều trị mới chẩn đoán bệnh chính xác hơn và
cải thiện hiệu quả chăm sóc
và trong ngành dịch vụ tài chính phân
tích big data dựa trên nền tảng đám mây đóng
vai trò quan trọng trong việc quản lý rủi ro và
phát hiện gian lận trong ngành dịch vụ tài
chính các nghiên cứu điển hình của 6 cho
thấy các tổ chức tài chính sử dụng big data
để xác định các giao dịch gian lận đánh giá
rủi ro tín dụng và quản lý danh mục đầu tư ví
dụ jpmorgan chase sử dụng big data để
phát hiện các trường hợp rửa tiền ngăn chặn
trang
gian lận thẻ tín dụng và tối ưu hóa danh mục
đầu tư
big data đang thay đổi cách thức hoạt
động của các doanh nghiệp trong nhiều lĩnh
vực các giải pháp big data dựa trên nền tảng
đám mây giúp doanh nghiệp tận dụng sức
mạnh của dữ liệu để đạt được lợi thế cạnh
tranh và thành công trong môi trường kinh
doanh đầy biến động bảng 2 sau đây thống
kê các ứng dụng
bảng 2 ứng dụng thực tiễn của big data
lĩnh vực
ứng dụng
ví dụ
nguồn trích dẫn
bán lẻ
quản lý hàng tồn kho cá nhân hóa
chiến dịch tiếp thị thu thập thông tin
chi tiết về khách hàng
amazon dự đoán nhu cầu
khách hàng đề xuất sản
phẩm phù hợp
chăm sóc
sức khỏe
phân tích dữ liệu bệnh nhân cải thiện
chất lượng chăm sóc thúc đẩy nghiên
mayo clinic phát triển
phương pháp điều trị mới
chẩn đoán chính xác hơn
dịch vụ tài
chính
quản lý rủi ro phát hiện gian lận
đánh giá rủi ro tín dụng quản lý danh
mục đầu tư
jpmorgan chase phát hiện
rửa tiền ngăn chặn gian lận
thẻ tín dụng tối ưu hóa danh
mục đầu tư
bảng 3 bảng so sánh lưu trữ truyền thống vs lưu trữ đám mây amazon s3
đặc điểm
lưu trữ truyền thống với tape qua băng đĩa
lưu trữ đám mây amazon s3
chi phí
chi phí trả trước cao cho phần cứng băng dung
lượng trung tâm dữ liệu và giấy phép phần mềm
mô hình trả tiền theo nhu cầu loại
bỏ chi phí trả trước
khả năng
mở rộng
khó mở rộng dung lượng lưu trữ cho nhu cầu dữ
liệu ngày càng tăng
dung lượng lưu trữ có thể mở rộng
cao để đáp ứng nhu cầu phát triển
của amazon
trang
đặc điểm
lưu trữ truyền thống với tape qua băng đĩa
lưu trữ đám mây amazon s3
hiệu suất
sao lưu và phục hồi chậm do thời gian đọc băng
sao lưu và phục hồi nhanh hơn đáng
kể so với băng
độ bền
cần nhiều bản sao lưu băng để đảm bảo độ bền dữ
liệu dễ bị lỗi phần cứng
lưu trữ cực kỳ bền vững với độ bền
số chín
quản lý
yêu cầu nhân viên có kỹ năng để quản lý cơ sở hạ
tầng băng
giảm khối lượng công việc với nhu
cầu quản lý tối thiểu
bảng 4 bảng so sánh máy chủ cục bộ vs aws ec2 đám mây
đặc điểm
máy chủ on premises
chuyển sang aws ec2
kết nối
phụ thuộc vào tài nguyên trong
trung tâm dữ liệu cục bộ
vpc và aws direct connect cung cấp các kết nối
chuyên dụng để giao tiếp liền mạch
độ phức tạp
của di chuyển
quá trình di chuyển phức tạp cho
máy chủ web cơ sở dữ liệu và
các công cụ
vpc và direct connect đơn giản hóa việc di
chuyển bằng cách mở rộng trung tâm dữ liệu vào
3 giải quyết thách thức và triển khai hiệu
quả big data dựa trên điện toán đám mây
mặc dù sự hội tụ của big data và điện
toán đám mây mang lại nhiều lợi ích nó cũng
đặt ra những thách thức cần được xem xét cẩn
thận bảo mật dữ liệu là một trong những
mối quan tâm hàng đầu pearson 7
đã nhấn mạnh tầm quan trọng của việc áp
dụng các biện pháp bảo mật thích hợp để bảo
vệ dữ liệu nhạy cảm trên đám mây các biện
pháp này bao gồm mã hóa dữ liệu kiểm soát
quyền truy cập và tuân thủ các quy định
mã hóa mạnh mẽ là dữ liệu cần được mã
hóa bằng các thuật toán mạnh để ngăn chặn
truy cập trái phép kiểm soát quyền truy cập
là sự thiết lập các quy trình kiểm soát chặt chẽ
để xác định người dùng nào có quyền truy cập
vào dữ liệu và mức độ truy cập của dữ liệu đó
trang
đối với việc tuân thủ các quy định như là
doanh nghiệp cần tuân thủ các quy định về
bảo mật dữ liệu chẳng hạn như quy định về
bảo vệ dữ liệu gdpr của liên minh châu
quản trị dữ liệu là một yếu tố quan trọng
khác cần được xem xét khi triển khai các giải
pháp big data trên nền tảng đám mây
achanta 8 và setiyawan patel
9 đã nêu bật tầm quan trọng của
việc chất lượng dữ liệu và tuân thủ quy định
đảm bảo chất lượng dữ liệu thực hiện bằng
việc xem xét dữ liệu tính chính xác đầy đủ
và nhất quán để có thể phân tích hiệu quả
doanh nghiệp cần tuân thủ các quy định về
quản lý dữ liệu chẳng hạn như sarbanes
oxley act sox của hoa kỳ
ngoài ra còn có một số thách thức khác
cần được xem xét khi triển khai các giải pháp
big data trên nền tảng đám mây bao gồm sự
tương tác kỹ năng nhân sự và chi phí triển
khai vận hành về khả năng tương tác thì
các giải pháp big data và điện toán đám mây
cần tương thích với các hệ thống hiện có của
doanh nghiệp đối với các kỹ năng thì doanh
nghiệp cần có nhân viên có kỹ năng cần thiết
để sử dụng các giải pháp big data và điện toán
đám mây còn lại đối với quản lý chi phí thì
doanh nghiệp cần tính toán chi phí triển khai
và vận hành các giải pháp big data và điện
toán đám mây
bằng cách xem xét cẩn thận những thách
thức và cân nhắc này các doanh nghiệp có thể
tận dụng hiệu quả sức mạnh của big data và
điện toán đám mây để đạt được lợi thế cạnh
tranh bảng 3
bảng 5 giải quyết thách thức và triển khai hiệu quả big data dựa trên điện toán đám mây
thách thức
giải pháp
nguồn trích dẫn
bảo mật dữ liệu
mã hóa mạnh mẽ kiểm soát quyền truy
cập tuân thủ quy định
quản trị dữ liệu
đảm bảo chất lượng dữ liệu tuân thủ
quy định
khả năng tương tác
tương thích với hệ thống hiện có
kỹ năng
nâng cao kỹ năng nhân viên
chi phí
tính toán chi phí triển khai và vận hành
trang tương lai của việc ra quyết định dựa
trên dữ liệu
tương lai của việc ra quyết định dựa trên
dữ liệu sẽ được định hình bởi sự hội tụ ngày
càng tăng giữa big data và điện toán đám
mây các xu hướng mới nổi như điện toán
biên và điện toán không máy chủ hứa hẹn sẽ
cách mạng hóa cách thức doanh nghiệp quản
lý và sử dụng dữ liệu
theo banjanovic husaković
điện toán biên tích hợp phân tích big
data dựa trên nền tảng đám mây với xử lý dữ
liệu thời gian thực tại ranh giới của mạng
điều này cho phép doanh nghiệp truy cập và
phân tích dữ liệu từ các thiết bị iot và các
nguồn khác nhanh chóng và hiệu quả hơn
mcgrath brenner cho rằng
điện toán không máy chủ đơn giản hóa việc
phát triển và triển khai ứng dụng dựa trên dữ
liệu nhờ vậy doanh nghiệp có thể thúc đẩy
đổi mới và tăng trưởng nhanh hơn
sự kết hợp của big data điện toán đám
mây và các xu hướng mới nổi khác sẽ tạo ra
một tương lai nơi dữ liệu đóng vai trò trung
tâm trong việc ra quyết định đổi mới và tăng
trưởng bảng 4 doanh nghiệp cần nắm bắt
những xu hướng này để thành công trong thời
đại dữ liệu
bảng 6 tương lai của việc ra quyết định dựa trên dữ liệu
xu hướng
mô tả
tác động
nguồn trích dẫn
điện toán
tích hợp phân tích big data dựa
trên nền tảng đám mây với xử lý dữ
liệu thời gian thực tại ranh giới của
truy cập và phân tích dữ
liệu nhanh chóng hiệu quả
điện toán
không máy
đơn giản hóa việc phát triển và triển
khai ứng dụng dựa trên dữ liệu
thúc đẩy đổi mới và tăng
trưởng
kết luận
sự tích hợp của big data và điện toán
đám mây mang đến cho doanh nghiệp khả
năng lưu trữ xử lý và phân tích dữ liệu mạnh
mẽ nhờ đó doanh nghiệp có thể nâng cao
hiệu quả hoạt động hiểu rõ hơn về khách
hàng phát triển sản phẩm mới và gia tăng lợi
thế cạnh tranh việc nắm bắt sức mạnh của big
data và điện toán đám mây là yếu tố then chốt
để doanh nghiệp thành công trong kỷ nguyên
trang
để áp dụng big data và điện toán đám
mây hiệu quả doanh nghiệp cần xác định rõ
mục tiêu lựa chọn giải pháp phù hợp xây
dựng chiến lược quản trị dữ liệu đầu tư đào
tạo nhân viên và triển khai từng bước từ dự
án nhỏ đến mở rộng dần việc áp dụng thành
công sẽ mang lại lợi thế cạnh tranh và giúp
doanh nghiệp thành công trong kỷ nguyên số
với sự hoạch định cẩn trọng và thực thi
hiệu quả doanh nghiệp có thể khai thác sức
mạnh của big data và điện toán đám mây để
đạt được những lợi ích to lớn
tài liệu tham khảo
1 laney d 3d data management
controlling data velocity and variety
meta group research note 6
2 armbrust m griffith r joseph a d katz
r konwinski a lee g patterson d et al
cloud
computing
communications of the acm 4
3 dikaiakos m ka d mehra p pallis g
vakali a cloud computing
distributed internet computing for it and
scientific research ieee internet computing
4 chen w li j jin x j the
5 halamka j the argonaut project
charter life as a healthcare cio
6 rizvi s role of big data in financial
institutions for financial fraud ssrn electronic
journal 4
7 pearson s privacy security and trust in
cloud computing in pearson s yee g eds
privacy and security for cloud computing
computer
communications
networks
springer london
8 achanta m data governance in the age of
cloud computing strategies and considerations
international journal of science and research
9 setiyawan d patel c a proposed
model of it governance within cloud computing
and data management in higher education ssrn
electronic journal 6
agrawal d das s abbadi a big
data and cloud computing current state and
future
international
conference
proceeding
series
ghaleb e a a dominic p d d fati s m
muneer a ali r f the assessment of big
data adoption readiness with a technology
organization environment
framework
perspective
towards
healthcare
employees
sustainability
shamim s zeng j cho u s shariq s
m connecting big data management
capabilities with employee ambidexterity in
chinese multinational enterprises through the
mediation of big data value creation at the
employee level international business review
6 issn
trang
big data in cloud computing review and
science information technology ijcsit vol
el seoud s a el sofany h f abdelfattah
m a f mohamed r big data and
cloud computing trends and challenges
international journal of interactive mobile
technologies
banjanovic m l husaković a edge
ai reshaping the future of edge computing
artificial
intelligence
pi2023
mcgrath g brenner p r
serverless
computing
design
implementation and performance ieee
37th international conference on distributed
computing systems wor icdcsw
atlanta ga usa
icdcsw
amazon web services december
aws re invent ent drinking our own
champagne
video
rvices cloud
chavan a september how amazon
retail uses the aws cloud
medium
retrieved
amazon retail amazon com uses the aws cloud
87ed6f456ac8
view publication sta",3816
sybca-bigdata-ppt.pdf_0,sybca-bigdata-ppt.pdf,"introduction to big data
what is data
the quantities characters or symbols on which operations are performed by a computer
which may be stored and transmitted in the form of electrical signals and recorded on
magnetic optical or mechanical recording media
what is big data
big data is also data but with a huge size big data is a term used to describe a
collection of data that is huge in and yet growing exponentially with time in
short such data is so large and complex that none of the traditional data management
tools are able to store it or process it efficiently
extremely large data sets that may be analyzed computationally to reveal patterns
trends and association especially relating to human behavior and interaction are
known as big data
examples of big data
following are some the examples of big data
the new york stock exchange generates about one terabyte of new trade data per day
social media
the statistic shows that terabytes of new data get ingested into the databases of social
media site facebook every day this data is mainly generated in terms of photo and video
uploads message exchanges putting comments etc
a single jet engine can generate terabytes of data in minutes of flight time with many
thousand flights per day generation of data reaches up to many petabytes
twitter
equal to
size in bytes
1 bit
nibble
4 bits
1 2 rare
8 bits
kilobyte
bytes
megabyte
1 024kilobytes
gigabyte
1 megabytes
terrabyte
1 gigabytes
petabyte
1 terrabytes
exabyte
1 petabytes
zettabyte
1 exabytes
yottabyte
1 zettabytes
tabular representation of various memory sizes
characteristics of big data
the following are known as big data characteristics
2 velocity
3 variety
4 veracity
means how much data is generated now a days
organizations or human beings or systems are generating or getting
very vast amount of data say tb tera bytes to pb peta bytes to exa
byte eb and more
2 velocity
velocity means how fast produce data now a days organizations or
human beings or systems are generating huge amounts of data at very
fast rate
3 variety
variety means different forms of data now a days organizations or
human beings or systems are generating very huge amount of data at very fast
rate in different formats we will discuss in details about different formats of
data soon
4 veracity
veracity means the quality or correctness or accuracy of captured data
out of 4vs it is most important v for any big data solutions because without
correct information or data there is no use of storing large amount of data at
fast rate and different formats that data should give correct business value
types of digital data
1 structured
2 unstructured
3 semi structured
structured
any data that can be stored accessed and processed in the form of fixed format is
termed as a structured data
over the period of time talent in computer science has achieved greater success in
developing techniques for working with such kind of data where the format is well
known in advance and also deriving value out of it
extent typical sizes are being in the range of multiple zettabytes
do you know bytes equal to 1 zettabyte or one billion terabytes forms a zettabyte
looking at these figures one can easily understand why the name big data is
given and imagine the challenges involved in its storage and processing
do you know data stored in a relational database management system is one
example of a structured data
examples of structured data
an employee table in a database is an example of structured data
employee_id
employee_name
gender
department
salary_in_lacs
rajesh kulkarni
finance
pratibha joshi
female
admin
shushil roy
admin
shubhojit das
finance
priya sane
female
finance
unstructured
any data with unknown form or the structure is classified as unstructured data
in addition to the size being huge un structured data poses multiple challenges in terms
of its processing for deriving value out of it
a typical example of unstructured data is a heterogeneous data source containing a
combination of simple text files images videos etc
now day organizations have wealth of data available with them but unfortunately they
don t know how to derive value out of it since this data is in its raw form or unstructured
format
examples of un structured data
the output returned by google search
semi structured
semi structured data can contain both the forms of data
we can see semi structured data as a structured in form but it is actually not defined
with e g a table definition in relational dbms
example of semi structured data is a data represented in an xml file
examples of semi structured data
personal data stored in an xml file
rec name prashant rao name sex male sex age age rec
rec name seema r name sex female sex age age rec
rec name satish mane name sex male sex age age rec
rec name subrato roy name sex male sex age age rec
rec name jeremiah j name sex male sex age age rec
big data analytics
big data analytics
big data analytics is the process of collecting organizing and analyzing
large sets of data called big data to discover patterns and other useful
information
big data analytics can help organizations to better understand the
information contained within the data and will also help identify the data
that is most important to the business and future business decisions
analysts working with big data typically want the knowledge that comes
from analyzing the data
high performance analytics required
to analyze such a large of data big data analytics is typically
analytics data mining text mining forecasting and data optimization
collectively these processes are separate but highly integrated functions of
high performance analytics
using big data tools and software enables an organization to process extremely
relevant and can be analyzed to drive better business decisions in the future
the challenges
for most organizations big data analysis is a challenge consider the sheer
of data and the different formats of the
data both structured and unstructured data that is collected across the entire
organization and the many different ways different types of data can be
combined contrasted and analyzed to find patterns and other useful business
information
the first challenge is in breaking down data silos to access all data an
organization stores in different places and often in different systems
a second challenge is in creating platforms that can pull in unstructured data as
easily as structured data
this massive of data is typically so large that it s difficult to process
using traditional database and software methods
how big data analytics is used today
as the technology that helps an organization to break down data silos and analyze
data improves business can be transformed in all sorts of ways
today s advances in analyzing big data allow researchers to decode human dna in
minutes predict where terrorists plan to attack determine which gene is mostly likely
to be responsible for certain diseases and of course which ads you are most likely to
respond to on facebook
another example comes from one of the biggest mobile carriers in the world
france s orange launched its data for development project by releasing subscriber
data for customers in the ivory coast
the 2 5 billion records which were made anonymous included details on calls and
text messages exchanged between 5 million users
researchers accessed the data and sent orange proposals for how the data could serve
as the foundation for development projects to improve public health and safety
proposed projects included one that showed how to improve public safety by tracking
cell phone data to map where people went after emergencies another showed how to
use cellular data for disease containment source
the benefits of big data analytics
enterprises are increasingly looking to find actionable insights into their
data many big data projects originate from the need to answer specific
business questions with the right big data analytics platforms in place an
enterprise can boost sales increase efficiency and improve operations
customer service and risk management
webopedia parent company quinstreet surveyed enterprise decision
makers involved in big data purchases to learn which business areas
companies plan to use big data analytics to improve operations about half
customer retention help with product development and gain a competitive
advantage
notably the business area getting the most attention relates to increasing
efficiency and optimizing operations specifically percent of respondents
said that they use big data analytics to improve speed and reduce complexity
big data in healthcare
big data in education
big data in e commerce
big data in media and entertainment
big data in finance
big data in travel industry
big data in telecom
big data in automobile
1 big data in retail
the retail industry is the one that faces the most fierce competition of all retailers
constantly hunt for ways that will give them a competitive edge over others
customers are the real king sounds legit for the retail industry in particular
for retailers to thrive in this competitive world they need to understand their
customers in a better way if they are aware of their customers needs and how to
fulfill those needs in the best possible way then they know everything
check how big data act as a weapon for retailers to connect with their customers
big data in retail
through advanced analysis of their customer s data retailers are now able to
understand them from every angle possible they gather this data from various
sources such as social media loyalty programs etc
even a minute detail about any customer has now become significant for them they are
now closer to their customers than they have ever been this empowers them to provide
customers with more personalized services and predict their demands in advance
this helps them in building a loyal customer base some of the biggest names in the retail
world like walmart sears and holdings costco walgreens and many more now have big
data as an integral part of their organizations
a study by the national retail federation estimated that sales in november and december
are responsible for as much as of retail annual sales
2 big data in healthcare
big data and healthcare are an ideal match it complements the healthcare industry better
than anything ever will the amount of data the healthcare industry has to deal with is
unimaginable
gone are the days when healthcare practitioners were incapable of harnessing this data
from finding a cure to cancer to detecting ebola and much more big data has got it all
under its belt and researchers have seen some life saving outcomes through it
big data and analytics have given them the license to build more personalized
medications data analysts are harnessing this data to develop more and more effective
treatments identifying unusual patterns of certain medicines to discover ways for
developing more economical solutions is a common practice these days
explore how big data helps to speed up the treatment process big data in
healthcare
smart wearables have gradually gained popularity and are the latest trend among
people of all age groups this generates massive amounts of real time data in the
form of alerts which helps in saving the lives of the people
3 big data in education
when you ask people about the use of the data that an educational institute gathers the
majority of the people will have the same answer that the institute or the student might
need it for future references
even you had the same perception about this data didn t you but the fact is this data
holds enormous importance big data is the key to shaping the future of the people and
has the power to transform the education system for better
some of the top universities are using big data as a tool to renovate their academic
curriculum additionally universities can even track the dropout rates of the students
and are taking the required measures to reduce this rate as much as possible
4 big data in e commerce
one of the greatest revolutions this generation has seen is that of e commerce it is now part
and parcel of our routine life whenever we need to buy something the first thought that
provokes our mind is e commerce and not your surprise big data has been the face of it
some of the biggest e commerce companies of the world like amazon flipkart alibaba and
many more are now bound to big data and analytics is itself an evidence of the level of
popularity big data has gained in recent times
big data is now as important as anyone else in these organizations amazon the biggest e
commerce firm in the world and one of the pioneers of big data and analytics has big data as
the backbone of its system flipkart the biggest e commerce firm in india has one of the most
robust data platforms in the country
see how flipkart used big data to have one of the most robust data platforms
has ever witnessed it furnishes the companies with a degree view of its customers
companies then suggest customers accordingly customers now experience more personalized
experiences
5 big data in media and entertainment
media and entertainment industry is all about art and employing big data in it is a
sheer piece of art art and science are often considered to be the two completely
contrasting domains but when employed together they do make a deadly duo and big
data s endeavors in the media industry are a perfect example of it
viewers these days need content according to their choices only content that is
relatively new to what they saw the previous time earlier the companies
broadcasted the ads randomly without any kind of analysis
but after the advent of big data analytics in the industry companies now are
broadcast it for seeking maximum attention
customers are now the real heroes of the media and entertainment industry
courtesy to big data and analytics
6 big data in finance
the functioning of any financial organization depends heavily on its data and to safeguard that
data is one of the toughest challenges any financial firm faces data has been the second most
important commodity for them after money
even before big data gained popularity the finance industry was already conquering the
technical field in addition to it financial firms were among the earliest adopters of big data
and analytics
digital banking and payments are two of the most trending buzzwords around and big data
has been at the heart of it big data is bossing the key areas of financial firms such as fraud
detection risk analysis algorithmic trading and customer contentment
this has brought much needed fluency in their systems they are now empowered to focus
big data has now enhanced the financial system with answers to its hardest of the challenges
7 big data in travel industry
while big data is spreading like wildfire and various industries have been cooking its food
with it the travel industry was a bit late to realize its worth better late than never though
having a stress free traveling experience is still like a daydream for many
and now big data s arrival is like a ray of hope that will mark the departure of all the
hindrances in our smooth traveling experience
see how big data is revolutionizing the travel tourism sector
through big data and analytics travel companies are now able to offer more
customized traveling experience they are now able to understand their customer s
requirements in a much enhanced way
from providing them with the best offers to be able to make suggestions in real time
big data is certainly a perfect guide for any traveler big data is gradually taking the
window seat in the travel industry
8 big data in telecom
the telecom industry is the soul of every digital revolution that takes place around the world
with the ever increasing popularity of smartphones it has flooded the telecom industry with
massive amounts of data
and this data is like a goldmine telecom companies just need to know how to dig it properly
through big data and analytics companies are able to provide the customers with smooth
connectivity thus eradicating all the network barriers that the customers have to deal with
companies now with the help of big data and analytics can track the areas with the lowest as
well as the highest network traffics and thus doing the needful to ensure hassle free network
connectivity
big data alike other industries have helped the telecom industry to understand its customers
pretty well
telecom industries now provide customers with offers as customized as possible
big data has been behind the data revolution we are currently experiencing
9 big data in automobile
a business like an automobile has to be driven in order to get results b c forbes
and big data has now taken complete control of the automobile industry and is driving it
smoothly big data is driving the automobile industry towards some unbelievable and never
before results
the automobile industry is on a roll and big data is its wheels or i must say big data has given
wings to it big data has helped the automobile industry achieve things that were beyond our
imaginations
of its customers to turning our wildest dream of connected cars a reality big data is well
and truly driving the automobile industry crazy",2932
TNG_QUAN_V_D_LIU_LN_BIGDATA.pdf_0,TNG_QUAN_V_D_LIU_LN_BIGDATA.pdf,"tổng quan vӄ dӳ liӊu lӟn bigdata
ks nguyễn công hoan
trước đây chúng ta mới chỉ biết đến dữ liệu có cấu trúc structure data ngày
nay với sự kết hợp của dữ liệu và internet đã xuất hiện một dạng khác của dữ liệu big
data dịch là dữ liệu lớn dữ liệu này có thể từ các nguồn như hồ sơ hành chính giao
dịch điện tử dòng trạng thái status chia sẻ hình ảnh bình luận nhắn tin của chính
chúng ta nói cách khác chúng là dữ liệu được sản sinh qua quá trình chia sẻ thông tin
trực tuyến liên tục của người sử dụng để cung cấp cái nhìn tổng quan chúng tôi xin giới
thiệu tóm tắt những nét chính về dữ liệu lớn cũng như những cơ hội và thách thức mà dữ
liệu lớn mang lại
1 khái niӌm đặc trưng của dӳ liӌu lӟn và sự khác biӌt vӟi dӳ liӌu truyӆn thống
1 1 khái niệm về dữ liệu lớn
theo wikipedia big data là một thuật ngữ chỉ bộ dữ liệu lớn hoặc phức tạp mà các
phương pháp truyền thống không đӫ các ứng dөng để xử lủ dữ liệu này
theo gartner dữ liệu lớn là những nguồn thông tin có đặc điểm chung khối lượng lớn
tốc độ nhanh và dữ liệu định dạng dưới nhiều hình thức khác nhau do đó muốn khai thác
được đòi hỏi phải có hình thức xử lủ mới để đưa ra quyết định khám phá và tối ưu hóa
quy trình
1 2 nguồn hình thành dữ liệu và phương pháp khai thác và quản lý dữ liệu lớn
qua thống kê và tổng hợp nguồn dữ liệu lớn được hình thành chӫ yếu từ 6 nguồn
1 dữ liệu hành chính phát sinh từ chương trình cӫa một tổ chức có thể là chính phӫ
hay phi chính phӫ ví dө hồ sơ y tế điện tử ở bệnh viện hồ sơ bảo hiểm hồ sơ ngân
hàng 2 dữ liệu từ hoạt động thương mại phát sinh từ các giao dịch giữa hai thực
thể ví dө các giao dịch thẻ tín dөng giao dịch trên mạng bao gồm cả từ các thiết bị di
động 3 dữ liệu từ các thiết bị cảm biến như thiết bị chөp hình ảnh vệ tinh cảm biến
đường cảm biến khí hậu 4 dữ liệu từ các thiết bị theo dõi ví dө theo dõi dữ liệu từ
điện thoại di động gps 5 dữ liệu từ các hành vi ví dө như tìm kiếm trực tuyến về
một sản phẩm một dịch vө hay thông tin khác đọc các trang mạng trực tuyến 6 dữ
liệu từ các thông tin về ủ kiến quan điểm cӫa các cá nhân tổ chức trên các phương tiện
thông tin xã hội
phương pháp khai thác và quản lủ dữ liệu lớn hiện nay được thiết kế phù hợp dựa
theo các nguồn hình thành dữ liệu lớn mỗi nguồn dữ liệu lớn khác nhau sẽ có phương
pháp khai thác và quản lủ dữ liệu lớn khác nhau tuy nhiên hiện nay phần lớn các tổ
chức trên thế giới đều dùng hadoop ecosystem là giải pháp tối ưu để khai thác và quản lủ
dữ liệu lớn
1 3 đặc trưng 5v c a dữ liệu lớn
dữ liệu lớn có 5 đặc trưng cơ bản như sau mô hình 5v
1 khối lượng dữ liệu
đây là đặc điểm tiêu biểu nhất cӫa dữ liệu lớn khối lượng dữ liệu rất lớn kích cỡ
cӫa big data đang từng ngày tăng lên và tính đến năm thì nó có thể nằm trong
khoảng vài chөc terabyte cho đến nhiều petabyte 1 petabyte terabyte chỉ cho
một tập hợp dữ liệu dữ liệu truyền thống có thể lưu trữ trên các thiết bị đĩa mềm đĩa
cứng nhưng với dữ liệu lớn chúng ta sẽ sử dөng công nghệ đám mây mới đáp ứng khả
năng lưu trữ được dữ liệu lớn
2 tốc độ velocity
tốc độ có thể hiểu theo 2 khía cạnh a khối lượng dữ liệu gia tăng rất nhanh mỗi
giây có tới 9 triệu các yêu cầu truy cập tìm kiếm trên web bán hàng cӫa amazon b
xử lủ dữ liệu nhanh ở mức thời gian thực real time có nghĩa dữ liệu được xử lủ ngay
tức thời ngay sau khi chúng phát sinh tính đến bằng mili giây các ứng dөng phổ biến
trên lĩnh vực internet tài chính ngân hàng hàng không quân sự y tế sức khỏe như
hiện nay phần lớn dữ liệu lớn được xử lủ real time công nghệ xử lủ dữ liệu lớn ngày nay
đã cho phép chúng ta xử lủ tức thì trước khi chúng được lưu trữ vào cơ sở dữ liệu
3 đa dạng variety
đối với dữ liệu truyền thống chúng ta hay nói đến dữ liệu có cấu trúc thì ngày nay
hơn dữ liệu được sinh ra là phi cấu trúc tài liệu blog hình ảnh vi deo bài hát dữ
liệu từ thiết bị cảm biến vật lủ thiết bị chăm sóc sức khỏe big data cho phép liên kết
và phân tích nhiều dạng dữ liệu khác nhau ví dө với các bình luận cӫa một nhóm người
dùng nào đó trên facebook với thông tin video được chia sẻ từ youtube và twitter
4 độ tin cậy chính xác veracity
một trong những tính chất phức tạp nhất cӫa dữ liệu lớn là độ tin cậy chính xác cӫa
dữ liệu với xu hướng phương tiện truyền thông xã hội social media và mạng xã hội
social network ngày nay và sự gia tăng mạnh mẽ tính tương tác và chia sẻ cӫa người
dùng mobile làm cho bức tranh xác định về độ tin cậy chính xác cӫa dữ liệu ngày một
khó khăn hơn bài toán phân tích và loại bỏ dữ liệu thiếu chính xác và nhiễu đang là tính
chất quan trọng cӫa bigdata
5 giá trị value
giá trị là đặc điểm quan trọng nhất cӫa dữ liệu lớn vì khi bắt đầu triển khai xây
dựng dữ liệu lớn thì việc đầu tiên chúng ta cần phải làm đó là xác định được giá trị cӫa
thông tin mang lại như thế nào khi đó chúng ta mới có quyết định có nên triển khai dữ
liệu lớn hay không nếu chúng ta có dữ liệu lớn mà chỉ nhận được 1 lợi ích từ nó thì
không nên đầu tư phát triển dữ liệu lớn kết quả dự báo chính xác thể hiện rõ nét nhất về
giá trị cӫa dữ liệu lớn mang lại ví dө từ khối dữ liệu phát sinh trong quá trình khám
chữa bệnh sẽ giúp dự báo về sức khỏe được chính xác hơn sẽ giảm được chi phí điều trị
và các chi phí liên quan đến y tế
1 4 sự khác biệt giữa dữ liệu lớn với dữ liệu truyền thống
dữ liệu lớn khác với dữ liệu truyền thống ví dө kho dữ liệu data warehouse ở 4
điểm cơ bản dữ liệu đa dạng hơn lưu trữ dữ liệu lớn hơn truy vấn nhanh hơn độ chính
xác cao hơn
1 dữ liệu đa dạng hơn khi khai thác dữ liệu truyền thống dữ liệu có cấu trúc
chúng ta thường phải trả lời các câu hỏi dữ liệu lấy ra kiểu gì định dạng dữ liệu như thế
nào đối với dữ liệu lớn không phải trả lời các câu hỏi trên hay nói khác khi khai thác
phân tích dữ liệu lớn chúng ta không cần quan tâm đến kiểu dữ liệu và định dạng cӫa
chúng điều quan tâm là giá trị mà dữ liệu mang lại có đáp ứng được cho công việc hiện
tại và tương lai hay không
2 lưu trữ dữ liệu lớn hơn lưu trữ dữ liệu truyền thống vô cùng phức tạp và luôn
đặt ra câu hỏi lưu như thế nào dung lượng kho lưu trữ bao nhiêu là đӫ gắn kèm với câu
hỏi đó là chi phí đầu tư tương ứng công nghệ lưu trữ dữ liệu lớn hiện nay đã phần nào
có thể giải quyết được vấn đề trên nhờ những công nghệ lưu trữ đám mây phân phối lưu
trữ dữ liệu phân tán và có thể kết hợp các dữ liệu phân tán lại với nhau một cách chính
xác và xử lủ nhanh trong thời gian thực
3 truy vấn dữ liệu nhanh hơn dữ liệu lớn được cập nhật liên tөc trong khi đó
kho dữ liệu truyền thống thì lâu lâu mới được cập nhật và trong tình trạng không theo dõi
thường xuyên gây ra tình trạng lỗi cấu trúc truy vấn dẫn đến không tìm kiếm được thông
tin đáp ứng theo yêu cầu
4 độ chính xác cao hơn dữ liệu lớn khi đưa vào sử dөng thường được kiểm định
lại dữ liệu với những điều kiện chặt chẽ số lượng thông tin được kiểm tra thông thường
rất lớn và đảm bảo về nguồn lấy dữ liệu không có sự tác động cӫa con người vào thay
đổi số liệu thu thập
2 bͱc tranh tổng thể ͱng dụng dữ liệu lớn
dữ liệu lớn đã được ứng dөng trong nhiều lĩnh vực như hoạt động chính trị giao
thông y tế thể thao tài chính thương mại thống kê dưới đây là một số ví dө về ứng
dөng dữ liệu lớn
2 1 ͱng dụng dữ liệu lớn trong hoạt động chính trị
hình bên cho thấy tổng thống mỹ obama đã sử dөng
dữ liệu dữ liệu lớn để phөc vө cho cuộc tranh cử tổng thống
cӫa mình ông xây dựng một đội ngũ nhân viên chuyên đi
thu thập thông tin và phân tích dữ liệu thu được trong dự án
triển khai về dữ liệu lớn đội ngũ nhân viên này thu thập tất
cả thông tin về người dân ở các khu vực sau đó phân tích và
chỉ ra một số thông tin quan trọng về người dân mỹ như
thích đọc sách gì thích mua loại thuốc gì thích sử dөng phương tiện gì thậm chí còn
biết được cả thông tin về mẹ cӫa cử tri đó đã bỏ phiếu tín nhiệm ai ở lần bầu cử trước
trên cơ sở những thông tin này tổng thống obama đã đưa ra kế hoạch vận động phù
hợp giúp ông tái đắc cử tổng thống nước mỹ lần thứ 2
ngoài ra một số ứng dөng khác trong lĩnh vực chính trị mà dữ liệu lớn được áp
dөng như hệ thống chính phӫ điện tử phân tích quy định và việc tuân thӫ quy định
phân tích giám sát theo dõi và phát hiện gian lận mối đe dọa an ninh mạng
2 2 ͱng dụng dữ liệu lớn trong giao thông
sử dөng số liệu cdr trong quá khứ để ước lượng các
dòng giao thông trong thành phố vào các giờ cao điểm từ đó có
những kế hoạch phân luồng giao thông chi tiết hợp lủ giúp giảm
thiểu kẹt xe ngoài ra còn đưa ra thông tin cho người tham gia
giao thông được biết nếu muốn đi từ nơi này đến nơi khác thì nên
đi vào giờ nào để tránh kẹt xe hoặc đi đường nào là ngắn nhất v v ngoài ra dữ liệu lớn
còn giúp phân tích định vị người dùng thiết bị di động ghi nhận chi tiết cuộc gọi trong
thời gian thực và giảm thiểu tình trạng ùn tắc giao thông
2 3 ͱng dụng dữ liệu lớn trong y tế
trong y học các bác sĩ dựa vào số liệu trong các bệnh án
để đưa ra dự đoán về nguy cơ mắc bệnh đồng thời cũng đưa ra
được xu hướng lây lan cӫa bệnh ví dө ứng dөng google flu
trend là một trong những ứng dөng thành công cӫa google ứng
dөng này dựa trên từ khóa tìm kiếm ở một khu vực nào đó sau đó
bộ máy phân tích cӫa google sẽ phân tích và đối chiếu kết quả tìm
kiếm đó sau cùng là đưa ra dự báo về xu hướng dịch cúm tại khu
vực đó qua đó cho biết tình hình cúm tại khu vực đó sẽ diễn ra như thế nào để đưa ra các
giải pháp phòng tránh những kết quả mà google flu trend đưa ra hoàn toàn phù hợp
với báo cáo cӫa tổ chức y tế thế giới who về tình hình bệnh cúm tại các khu vực đó
2 4 ͱng dụng dữ liệu lớn trong thể thao
phân tích mô hình hệ thống cấu trúc sơ đồ chiến thuật
cӫa đội tuyển đức hình bên đã đưa ra những điểm bất hợp lủ
trong cấu trúc cӫa đội tuyển đức từ đó giúp cho đội tuyển đức
khắc phөc được điểm yếu và đã dành được world cup
2 5 ͱng dụng dữ liệu lớn trong tài chính
từ những dữ liệu chính xác kịp thời thu thập được thông qua các giao dịch cӫa
khách hàng tiến hành phân tích xếp hạng và quản lủ các rӫi ro trong đầu tư tài chính tín
2 6 ͱng dụng dữ liệu lớn trong thương mại
trong thương mại dữ liệu lớn giúp cho chúng ta thực hiện được một số công việc
sau phân khúc thị trường và khách hàng phân tích hành vi khách hàng tại cửa hàng tiếp
thị trên nền tảng định vị phân tích tiếp thị chéo kênh tiếp thị đa kênh quản lủ các chiến
dịch tiếp thị và khách hàng thân thiết so sánh giá phân tích và quản lủ chuỗi cung ứng
phân tích hành vi thói quen người tiêu dùng
2 7 ͱng dụng dữ liệu lớn trong thống kê
nhận thấy những lợi ích to lớn và thách thức cӫa bigdata đối với thống kê chính
thức ӫy ban thống kê liên hợp quốc cũng như các tổ chức thống kê khu vực và cơ quan
thống kê quốc gia cӫa nhiều nước đã triển khai hàng loạt các hoạt động về bigdata như
hàn quốc sử dөng ảnh vệ tinh để thống kê nông nghiệp và một số lĩnhvực khác australia
sử dөng ảnh vệ tinh để thống kê diện tích đất nông nghiệp và năng suất italia sử dөng dữ
liệu điện thoại di động để thống kê di cư bhutan dùng thiết bị di động để tính toán chỉ số
giá tiêu dùng estonia dùng điện thoại di động định vị vệ tinh để thống kê du lịch
eurostat sử dөng dữ liệu về sử dөng điện thoại di động để thống kê du lịch1
3 nhӳng cơ hội và thách thͱc khi ͱng dụng big data trong thống kê chính thͱc
3 1 cơ hội
1 tiếp cận và nghiên cứu về dữ liệu lớn sẽ giúp cho chúng ta có thêm phương án
giải quyết xử lủ và đối phó với những thách thức đối sản xuất số liệu thống kê chính thức
trong hiện tại và tương lai những nghiên cứu thực nghiệm cần phải được tiến hành để
khám phá những ứng dөng tiềm năng cӫa dữ liệu lớn trong số liệu thống kê chính thức
và nghiên cứu thực nghiệm đó phải là một phần trong quy trình sản xuất số liệu thống kê
2 nghiên cứu về dữ liệu lớn cần phải có cơ sở hạ tầng công nghệ thông tin hiện
đại đáp ứng các yêu cầu xử lủ khối lượng lớn dữ liệu và nhanh đồng thời có thể tập hợp
dữ liệu từ nhiều nguồn khác nhau thực hiện được điều này chúng ta có được đội ngũ
nguồn nhân lực về quản lủ và khai thác big data vững vàng về chuyên môn và được trải
qua kinh nghiệm thực tế
3 tiếp cận và nghiên cứu về dữ liệu lớn sẽ giúp chúng ta có được những văn bản
pháp lủ bổ sung có thể giúp cho cơ quan thống kê chính thức có điều kiện để thực hiện
được khai thác dữ liệu thông qua hồ sơ hành chính ngoài ra dữ liệu cũng được bảo đảm
và giữ bí mật nhờ những văn bản pháp lủ bổ sung này
4 sử dөng dữ liệu lớn đem lại niềm tin cӫa cộng đồng với thống kê chính thức do
quá trình trình sản xuất số liệu thống kê chính thức với dữ liệu lớn hoàn toàn không có sự
tác động chӫ ủ cӫa con người
3 2 thách thͱc
1 tài chính
nhiều đơn vị tổ chức không đo lường được vấn đề sẽ phát sinh trong quá trình triển
khai thực hiện dự toán kinh phí chưa chính xác do vậy dự án không thực hiện được để
triển khai được thành công yếu tố tài chính có ủ nghĩa rất quan trọng một số tập đoàn
thương mại lớn có tiềm lực tài chính vững chắc đã xây dựng thuận lợi hệ thống dữ liệu
big data như ibm website bán hàng thương mại điện tử amazon
2 chính sách quy định luật pháp về truy cập và sử dụng dữ liệu
việc sử dөng và khai thác dữ liệu lớn phө thuộc vào luật quy định cӫa mỗi quốc gia
1 xem báo cáo thống kê chính thức với big data kinh nghiệm quốc tế và định hướng của thống kê việt nam
ví dө ở canada người dùng có thể được tiếp cận dữ liệu từ cả hai tổ chức chính
phӫ và phi chính phӫ nhưng ở những nước khác như ireland thì phải được sự cho phép
từ các cơ quan chính phӫ điều này có thể dẫn đến những hạn chế để truy cập vào một số
loại dữ liệu lớn
3 trình độ khai thác và quản lý dữ liệu
do luật pháp quy định sử dөng và khai thác ở mỗi quốc gia là khác nhau nên cách
quản lủ là cũng khác nhau tuy nhiên một vấn đề liên quan đến quản lủ thông tin hiện nay
nhân trong khi đó bộ phận này chưa được liên kết với những tổ chức cӫa chính phӫ một
cách chặt chẽ dẫn đến việc quản lủ vẫn còn nhiều vướng mắc
4 hạ tầng công nghệ thông tin
cần phải cải thiện tốc độ dữ liệu truy cập vào các dữ liệu hành chính nghĩa là có thể
sử dөng giao diện ứng dөng cӫa chương trình chuyên sâu tiêu chuẩn api để truy cập
dữ liệu bằng cách này nó có thể kết nối các ứng dөng cho dữ liệu thu về và xử lủ dữ liệu
trực tiếp với dữ liệu hành chính ngoài ra hệ thống khai thác dữ liệu lớn cũng cần phải
được tính toán để có thể kết nối vào được kho cơ sở dữ liệu truyền thống đó cũng là một
trong những thách thức lớn cần được giải quyết
tóm lại
trong bài nghiên cứu trên chúng tôi đã đưa ra được những thông tin cơ bản về big
data những lợi ích mà big data mang lại cho chúng ta bên cạnh đó cũng chỉ ra những
thách thức khi triển khai áp dөng khai thác big data
điều quan trọng nhất trong báo cáo này đã đưa ra những ưu điểm cӫa big data đó là
cung cấpthông tin để chung ta xử lủ được tình huống nhanh nhất chính xác nhất và giá trị
cӫa big data mang lại luôn có tính định hướng đến tương lai giải đáp những câu hỏi tại
sao việc ấy lại xảy ra sau chuyện đó thì điều gì sẽ sảy ra và chúng ta nên ứng phó như
thế nào trong hoàn cảnh đó
tài liệu tham khảo
1 tài liệu cơ hội và thách thức với bigdata e cӫa liên hợp quốc
2 báo cáo hội thảo về tương lai cӫa thống kê học london
3 tài liệu về các khái niệm và đặc trưng cӫa big data",3418
what-is-big-data-ebook-4421383.pdf_0,what-is-big-data-ebook-4421383.pdf,"what is big data
enter
table of contents
defntion of big data
the history of big data
big data use cases
how big data works
big data best practices
put big data to work
defnition of
big data
what exactly is big data
to put it simply big data is larger more
complex data sets especially from new data
sources these data sets are so voluminous that
traditional data processing software just can t
data can be used to address business problems
you wouldn t have been able to tackle before
to really understand big data it s helpful to have
some historical background here s gartner s
defnition circa which is still the go to
defnition
big data is data that contains greater variety
higher velocity this is known as the three vs
the three vs of big data
the amount of data matters with
of low density unstructured data this can be
data of unknown value such as twitter data
feeds clickstreams on a webpage or a mobile
organizations this might be tens of
terabytes of data for others it may be
hundreds of petabytes
velocity velocity is the fast rate at which data
is received and perhaps acted on normally
the highest velocity of data streams directly into
memory versus being written to disk some
internet enabled smart products operate in real
time or near real time and will require
real time evaluation and action
variety in today s big data world data
comes in new unstructured data types
unstructured and semi structured data types
such as text audio and video require addition
preprocessing to derive meaning and
velocity
variety
big data
the value and truth of
big data
value and veracity data has intrinsic value but
it s of no use until that value is discovered
equally important how truthful is your data and
how much can you rely on it
today big data has become capital think of
some of the world s biggest tech companies a
large part of the value they offer comes from
their data which they re constantly analyzing to
produce more effciency and develop
new products
recent technological breakthroughs have
exponentially reduced the cost of data storage
and compute making it easier and less expensive
to store more data than ever before with an
increased of big data now cheaper and
more accessible you can make more accurate
and precise business decisions
finding value in big data isn t only about
analyzing it which is a whole other beneft
it s an entire discovery process that requires
insightful analysts business users and
executives who ask the right questions recognize
patterns make informed assumptions and
predict behavior
but how did we get here
the history
of big data
around people began to realize just how
much data users generated through facebook
youtube and other online services hadoop an
open source framework created specifcally to
store and analyze big data sets was developed
that same year nosql also began to gain
popularity during this time
the development of open source frameworks
such as hadoop and more recently spark was
essential for the growth of big data because they
make big data easier to work with and cheaper to
store in the years since then the of big
data has skyrocketed users are still generating
huge amounts of data but it s not just humans
with the advent of internet of things iot more
objects and devices are connected to the internet
gathering data on customer usage patterns and
product performance the emergence of machine
learning has produced still more data
while big data has come far its popularity is only
just beginning cloud computing has expanded
big data possibilities even further
the cloud offers a truly elastic scalability where
developers can just spin up ad hoc clusters to
test around a subset of data it s an exciting time
benefits of big data and
data analytics
the value of big data comes is twofold
1 big data makes it possible for you to gain
more complete answers because you have
more information
2 more complete answers means more
confdence in the data which means
tackling problems
big data
use cases
this new knowledge enables you to handle use
cases that you haven t been able to fully delve
into before here are just a few more use cases
are on our solutions page
product development
companies like netfix and procter gamble
use big data to anticipate customer demand
by classifying key attributes of past and current
products or services and then modeling the
relationship between those attributes and the
commercial success of the offerings they build
predictive models for new products and services
in addition p g uses data and analytics from
focus groups social media test markets and
early store rollouts to plan produce and launch
new products
predictive maintenance
factors that can predict mechanical failures may
be deeply buried in structured data such as the
equipment year make and model as well as
in unstructured data that covers millions of log
entries senor data error messages and engine
temperature by analyzing these indications of
organizations can deploy maintenance more cost
effectively and maximize parts and
equipment uptime
customer experience
the race for customers is on a clearer view of
customer experience is more possible now than
ever before big data enables you to gather data
from social media web visits call logs and
other data sources to improve the interaction
experience and maximize the value delivered
start delivering personalized offers reduce
fraud and compliance
when it comes to security it s not just a few
rogue hackers you re up against entire expert
teams security landscapes and compliance
requirements are constantly evolving big
data helps you identify patterns in data that
information to make regulatory reporting
much faster
machine learning
machine learning is the hottest of hot topics right
now and data specifcally big data is one of
the reasons why it s only recently that we ve
been able to teach machines instead of program
them and the availability of big data to train
operational efficiency
operational effciency may not always make the
news but it s an area in which big data is having
the most impact with big data you can analyze
and assess production customer feedback and
returns and other factors to reduce outages and
anticipate future demands big data can also be
used to improve decision making in line with
current market demand
drive innovation
big data can help you innovate by studying
interdependencies between humans institutions
entities and process and then determining new
ways to use those insights use data insights to
improve decisions about fnancial and planning
considerations examine trends and what
customers want to deliver new products and
services implement dynamic pricing there are
endless possibilities
big data challenges
while big data holds a lot of promise it is not
without its challenges
first big data is big although new
technologies have been developed to store data
two years organizations still struggle to keep
pace with their data and fnd ways to effectively
store it
but it s not enough to just store the data data
must be used to be valuable and that depends
on curation clean data or data that s relevant
to the client and organized in a way that enables
meaningful analysis requires a lot of work
data scientists spend to percent of their
time curating and preparing data before it can
actually be used
finally big data technology is changing at a fast
pace a few years ago apache hadoop was the
popular technology used to handle big data that
is until apache spark was introduced in
today a combination of the two frameworks
big data technology is an ongoing challenge
how big
data works
oracle cloud for big data analytics
public
streaming
enterprise
providers
data services
business analytics
consumers
integrate
analyze
manage
adaptive
intelligence
big data gives you new insights that open up
started involves three key actions
integrate
big data brings together data from many
data integration mechanisms such as etl
extract transform and load generally aren t
up to the task it requires new strategies and
technologies to analyze big data sets at terabyte
or even petabyte scale at the same time big
data has the same requirements for quality
governance and confdence as traditional data
sources during integration you need to bring in
the data process it and make sure it s formatted
and available in a form that your business
analysts can get started with
manage
big data requires storage your storage solution
can be in the cloud on premises or both
you can store your data in any form you want
and bring your desired processing requirements
and necessary process engines to those data sets
on an on demand basis many people choose
their storage solution according to where their
data is currently residing the cloud is gradually
current compute requirements and enables you
to spin up resources as needed
analyze
your investment in big data pays off when you
analyze and act on your data get new clarity with
a visual analysis of your varied data sets explore
the data further to make new discoveries share
your fndings with others build data models with
machine learning and artifcial intelligence put
your data to work
to help you on your big data journey we ve put
together some key best practices for you to keep
in mind here are our guidelines for building a
successful big data foundation
big data
best practices
1 align big data with
specific business goals
more extensive data sets enable you to make
new discoveries to that end it is important to
base new investments in skills organization
or infrastructure with a strong business
driven context to guarantee ongoing project
investments and funding to determine if
you are on the right track ask how big data
priorities examples include understanding how
to flter web logs to understand ecommerce
behavior deriving sentiment from social
understanding statistical correlation methods
and their relevance for customer product
manufacturing and engineering data
2 ease skills shortage
with standards and
governance
one of the biggest obstacles to big data is a skills
shortage you can mitigate this risk by ensuring
that big data technologies considerations
and decisions are added to your it
governance program
to manage costs and leverage resources
organizations implementing big data
solutions and strategies should assess their
skill requirements early and often and should
proactively identify any potential skill gaps these
can be addressed by training cross training
existing resources hiring new resources and
leveraging consulting frms
3 optimize knowledge
transfer with a center
of excellence
knowledge control oversight and manage
project communications whether big data is a
new or an expanding investment the soft and
hard costs can be shared across the enterprise
big data capabilities and overall information
architecture maturity in a more structured and
systematic way
4 top payoff is aligning
unstructured with
structured data
it is certainly valuable to analyze big data on its
own but you can bring even greater business
insights by connecting and integrating low
density big data with the structured data you are
already using today
whether you are capturing customer product
equipment or environmental big data the goal
is to add more relevant data points to your
core master and analytical summaries leading
to better conclusions for example there is
a difference in distinguishing all customer
sentiment from that of only your best customers
which is why many see big data as an integral
extension of their existing business intelligence
capabilities data warehousing platform and
information architecture
keep in mind that the big data analytical
processes and models can be both human and
machine based big data analytical capabilities
include statistics spatial analysis semantics
interactive discovery and visualization using
analytical models you can correlate different
types and sources of data to make associations
and meaningful discoveries
5 plan your discovery lab
for performance
discovering meaning in your data is not always
straightforward sometimes we don t even
know what we re looking for that s expected
of direction or lack of clear requirement
at the same time it s important for analysts and
data scientists to work closely with the business
to understand key business knowledge gaps and
requirements to accommodate the interactive
exploration of data and the experimentation of
statistical algorithms you need high performance
work areas be sure that sandbox environments
have the power they need and are
properly governed
6 align with the cloud
operating model
big data processes and users require access
to broad array of resources for both iterative
experimentation and running production
jobs a big data solution includes all data
realms including transactions master data
reference data and summarized data analytical
sandboxes should be created on demand
resource management is critical to ensure
control of the entire data fow including pre
and post processing integration in database
summarization and analytical modeling a well
planned private and public cloud provisioning
and security strategy plays an integral role in
put big data
to work
clearly big data has tremendous potential
putting a big data initiative to work at your
organization can help you better understand your
customers make more accurate decisions and
learn more
see how oracle can help your big data journey
start your free trial today
contact us url
sales html
free trial url
copyright oracle and or its affiliates all rights reserved this document is provided for information purposes only and the contents hereof are subject
to change without notice this document is not warranted to be error free nor subject to any other warranties or conditions whether expressed orally or
worldwide headquarters
implied in law including implied warranties and conditions of merchantability or fitness for a particular purpose we specifically disclaim any liability with
oracle parkway
redwood shores
respect to this document and no contractual obligations are formed either directly or indirectly by this document this document may not be reproduced or
transmitted in any form or by any means electronic or mechanical for any purpose without our prior written permission
oracle and java are registered trademarks of oracle and or its affiliates other names may be trademarks of their respective owners
intel and intel xeon are trademarks or registered trademarks of intel corporation all sparc trademarks are used under license and are trademarks or
registered trademarks of sparc international inc amd opteron the amd logo and the amd opteron logo are trademarks or registered trademarks of
worldwide inquiries
advanced micro devices unix is a registered trademark of the open group
phone 1
1 oracle1
connect with us",2436
